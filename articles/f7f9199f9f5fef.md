---
title: "PCAã®æ•°ç†è§£èª¬ã¨å®Ÿè£…(PyTorch)"
emoji: "ğŸ"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["AI", "æ©Ÿæ¢°å­¦ç¿’", "ç·šå½¢ä»£æ•°", "Python", "PyTorch", "æ¬¡å…ƒå‰Šæ¸›"]
published: false
---

## ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ã®æ•°ç†è§£èª¬

PCAã‚’ãŒã£ã¤ã‚Šèª¬æ˜ã—ã¦ã‚‹è¨˜äº‹ã‚’ã‚ã¾ã‚Šè¦‹ãªã„ã®ã§ï¼ˆéœ€è¦ãŒãªã„...ï¼‰PCAã®Pytorchå®Ÿè£…ï¼ˆGPUå¯¾å¿œï¼‰ã®ã¤ã„ã§ã«ã‚„ã£ã¦ã¿ã¾ã—ãŸã€‚æœ¬ç¨¿ã¯åˆæŠ•ç¨¿ã¨ãªã‚Šã¾ã™ãŒã€ä»Šå¾Œã‚‚ã“ã‚“ãªæ„Ÿã˜ã§å‹‰å¼·ã¨å®Ÿè£…ã‚’ç¶™ç¶šã—ã¦ã§ããŸã‚‰ãªï½ã¨æ€ã„ã¾ã™ã€‚

### 0. è¨˜å·ã®å®šç¾©

#### 0.1 æ¬¡å…ƒãƒ»æ·»å­—

* $N\in\mathbb{N}$ ï¼šã‚µãƒ³ãƒ—ãƒ«æ•°
* $d\in\mathbb{N}$ ï¼šç‰¹å¾´æ¬¡å…ƒ
* $k\in\mathbb{N}$ ï¼šä¿æŒã™ã‚‹ä¸»æˆåˆ†æ•°ï¼ˆ $1\le k\le \min(N,d)$ ï¼‰
* æ·»å­—ï¼šã‚µãƒ³ãƒ—ãƒ« $i\in\{1,\dots,N\}$ ã€ç‰¹å¾´ $j\in\{1,\dots,d\}$ ã€ä¸»æˆåˆ† $m\in\{1,\dots,k\}$

#### 0.2 ãƒ™ã‚¯ãƒˆãƒ«ãƒ»è¡Œåˆ—

* ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—

$$
\mathbf{X}\in\mathbb{R}^{N\times d},
\qquad
\mathbf{X}=
\begin{bmatrix}
\mathbf{x}_1^\top\\
\vdots\\
\mathbf{x}_N^\top
\end{bmatrix}
$$

  ã“ã“ã§ $\mathbf{x}_i\in\mathbb{R}^{d}$ ã¯ç¬¬ $i$ ã‚µãƒ³ãƒ—ãƒ«ï¼ˆåˆ—ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã§ã‚ã‚‹ã€‚
* å…¨1ãƒ™ã‚¯ãƒˆãƒ«

$$
\mathbf{1}_N\in\mathbb{R}^{N}
$$

* å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆåˆ—å¹³å‡ï¼‰

$$
\boldsymbol{\mu}\in\mathbb{R}^{d}
$$

* ä¸­å¿ƒåŒ–å¾Œãƒ‡ãƒ¼ã‚¿

$$
\mathbf{X}_c\in\mathbb{R}^{N\times d}
$$

* å…±åˆ†æ•£è¡Œåˆ—ï¼ˆåˆ†æ¯ $N$ ã‚’æ¡ç”¨ï¼‰

$$
\mathbf{S}\in\mathbb{R}^{d\times d}
$$

* å›ºæœ‰ç›´äº¤åˆ†è§£

$$
\mathbf{S}=\mathbf{Q}\boldsymbol{\Lambda}\mathbf{Q}^\top
$$

* ç‰¹ç•°å€¤åˆ†è§£

$$
\mathbf{X}_c=\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^\top
$$

* ä¸»æˆåˆ†æ–¹å‘ï¼ˆloadingsï¼‰

$$
\mathbf{W}\in\mathbb{R}^{d\times k}
$$

* ä¸»æˆåˆ†å¾—ç‚¹ï¼ˆscoresï¼‰

$$
\mathbf{Z}\in\mathbb{R}^{N\times k}
$$

* èª¬æ˜åˆ†æ•£ï¼ˆä¸»æˆåˆ†åˆ†æ•£ï¼‰

$$
\lambda_m\quad(m=1,\dots,k)
$$

* èª¬æ˜åˆ†æ•£æ¯”ï¼ˆä¿æŒã—ãŸ $k$ æˆåˆ†å†…ã§æ­£è¦åŒ–ï¼‰

$$
\mathrm{EVR}_m:=\frac{\lambda_m}{\sum_{j=1}^k\lambda_j}
$$

---

### 1. ä¸­å¿ƒåŒ–ï¼ˆå¹³å‡ã®é™¤å»ï¼‰

PCAã¯ã€Œå¹³å‡ã‹ã‚‰ã®ã°ã‚‰ã¤ãã€ã‚’æ‰±ã†ãŸã‚ã€å„ç‰¹å¾´ã‚’ä¸­å¿ƒåŒ–ã™ã‚‹ã€‚

å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’

$$
\boldsymbol{\mu}:=\frac{1}{N}\sum_{i=1}^{N}\mathbf{x}_i\in\mathbb{R}^{d}
$$

ã¨å®šç¾©ã™ã‚‹ã€‚è¡Œåˆ—è¡¨è¨˜ã§ã¯

$$
\boldsymbol{\mu}=\frac{1}{N}\mathbf{X}^\top\mathbf{1}_N.
$$

ä¸­å¿ƒåŒ–ãƒ‡ãƒ¼ã‚¿ã¯

$$
\mathbf{X}_c:=\mathbf{X}-\mathbf{1}_N\boldsymbol{\mu}^\top\in\mathbb{R}^{N\times d}
$$

ã§ã‚ã‚‹ã€‚

---

### 2. å…±åˆ†æ•£è¡Œåˆ—ã¨ãã®æ€§è³ª

å…±åˆ†æ•£è¡Œåˆ—ã‚’

$$
\mathbf{S}:=\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c\in\mathbb{R}^{d\times d}\tag{2.1}
$$

ã¨å®šç¾©ã™ã‚‹ï¼ˆåˆ†æ¯ $N$ ï¼‰ã€‚

#### 2.1 å¯¾ç§°æ€§

$$
\mathbf{S}^\top=\left(\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c\right)^\top=\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c=\mathbf{S}.
$$

å¯¾ç§°è¡Œåˆ—ã§ã‚ã‚Œã°ã€ç•°ãªã‚‹å›ºæœ‰å€¤ã«å¯¾å¿œã™ã‚‹å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã¯å¿…ãšç›´äº¤ã™ã‚‹ã€‚

#### 2.2 åŠæ­£å®šå€¤æ€§ï¼ˆPSDï¼‰

ä»»æ„ã® $\mathbf{a}\in\mathbb{R}^d$ ã«å¯¾ã—ã¦

$$
\mathbf{a}^\top\mathbf{S}\mathbf{a}=\frac{1}{N}\mathbf{a}^\top\mathbf{X}_c^\top\mathbf{X}_c\mathbf{a}=\frac{1}{N}\|\mathbf{X}_c\mathbf{a}\|_2^2\ge 0.
$$

å¾“ã£ã¦ $\mathbf{S}$ ã¯å¯¾ç§°åŠæ­£å®šå€¤ã§ã‚ã‚‹ï¼ˆåˆ†æ•£ã‚„ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒãƒã‚¤ãƒŠã‚¹ã«ãªã‚‹ã“ã¨ã¯ãªã„ãŸã‚ã€åŠæ­£å®šå€¤ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰ã€‚

ã“ã®æ€§è³ªã‹ã‚‰ã€$\mathbf{S}$ ã¯å›ºæœ‰ç›´äº¤åˆ†è§£

$$
\mathbf{S}=\mathbf{Q}\boldsymbol{\Lambda}\mathbf{Q}^\top,
\qquad
\mathbf{Q}^\top\mathbf{Q}=\mathbf{I},
\qquad
\boldsymbol{\Lambda}=\mathrm{diag}(\lambda^\ast_1,\dots,\lambda^\ast_d),
\quad
\lambda^\ast_1\ge\dots\ge\lambda^\ast_d\ge 0
\tag{2.2}
$$

ã‚’æŒã¤ã€‚

---

### 3. PCAã®å®šå¼åŒ–ï¼šç­‰ä¾¡ãª2ã¤ã®æœ€é©åŒ–å•é¡Œ

PCAã¯ä»£è¡¨çš„ã«æ¬¡ã®2ã¤ã®å•é¡Œã¨ã—ã¦å®šç¾©ã§ãã€ã“ã‚Œã‚‰ã¯ç­‰ä¾¡ã§ã‚ã‚‹ã€‚

#### 3.1 å°„å½±å†æ§‹æˆèª¤å·®ã®æœ€å°åŒ–ï¼ˆæœ€å°äºŒä¹—ï¼‰

$\mathbf{W}\in\mathbb{R}^{d\times k}$ ãŒåˆ—ç›´äº¤

$$
\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k
\tag{3.1}
$$


ã‚’æº€ãŸã™ã¨ã™ã‚‹ã€‚å°„å½±è¡Œåˆ—ã‚’
$$
\mathbf{P}:=\mathbf{W}\mathbf{W}^\top
\in\mathbb{R}^{d\times d}
\tag{3.2}
$$

ã¨å®šç¾©ã™ã‚‹ã¨ã€ä¸­å¿ƒåŒ–ãƒ‡ãƒ¼ã‚¿ã®å°„å½±å†æ§‹æˆã¯

$$
\widehat{\mathbf{X}}_c=\mathbf{X}_c\mathbf{P}=\mathbf{X}_c\mathbf{W}\mathbf{W}^\top.
\tag{3.3}
$$

ã“ã®ã¨ã PCA ã¯

$$
\min_{\mathbf{W}}\
\left\|\mathbf{X}_c-\mathbf{X}_c\mathbf{W}\mathbf{W}^\top\right\|_F^2
\quad\text{s.t.}\quad
\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k
\tag{P1}
$$

ã‚’è§£ãã“ã¨ã¨ã—ã¦å®šç¾©ã§ãã‚‹ã€‚

#### 3.2 å°„å½±å¾Œåˆ†æ•£ã®æœ€å¤§åŒ–

ã‚¹ã‚³ã‚¢ï¼ˆä½æ¬¡å…ƒè¡¨ç¾ï¼‰ã‚’

$$
\mathbf{Z}:=\mathbf{X}_c\mathbf{W}\in\mathbb{R}^{N\times k}\tag{3.4}
$$

ã¨å®šç¾©ã™ã‚‹ã€‚ã™ã‚‹ã¨

$$
\mathbf{Z}^\top\mathbf{Z}=\mathbf{W}^\top\mathbf{X}_c^\top\mathbf{X}_c\mathbf{W}.\tag{3.5}
$$

ã‚ˆã£ã¦ $\mathbf{S}=\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c$ ã‚ˆã‚Šã€ã‚¹ã‚³ã‚¢ã®ç·åˆ†æ•£ã¯

$$
\frac{1}{N}\mathrm{tr}(\mathbf{Z}^\top\mathbf{Z})=
\mathrm{tr}\left(\mathbf{W}^\top\mathbf{S}\mathbf{W}\right).
\tag{3.6}
$$

å¾“ã£ã¦ PCA ã¯

$$
\max_{\mathbf{W}}\
\mathrm{tr}\left(\mathbf{W}^\top\mathbf{S}\mathbf{W}\right)
\quad\text{s.t.}\quad
\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k
\tag{P2}
$$

ã¨ã—ã¦ã‚‚è¡¨ã›ã‚‹ï¼ˆKy Fan ã®æœ€å¤§åŒ–å•é¡Œï¼‰ã€‚

---

### 4. (P1) ã¨ (P2) ã®ç­‰ä¾¡æ€§

(P1) ã®ç›®çš„é–¢æ•°ã‚’å±•é–‹ã™ã‚‹ã€‚ã¾ãš Frobenius ãƒãƒ«ãƒ ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã§æ›¸ãï¼š

$$
\|\mathbf{A}\|_F^2=\mathrm{tr}(\mathbf{A}^\top\mathbf{A}).
$$

$\mathbf{A}:=\mathbf{X}_c-\mathbf{X}_c\mathbf{P}$ ã¨ç½®ã‘ã°

$$
\|\mathbf{X}_c-\mathbf{X}_c\mathbf{P}\|_F^2=\mathrm{tr}\left((\mathbf{X}_c-\mathbf{X}_c\mathbf{P})^\top(\mathbf{X}_c-\mathbf{X}_c\mathbf{P})\right).
\tag{4.1}
$$


å³è¾ºã‚’å±•é–‹ã™ã‚‹ã¨

$$
(\mathbf{X}_c-\mathbf{X}_c\mathbf{P})^\top(\mathbf{X}_c-\mathbf{X}_c\mathbf{P})=\mathbf{X}_c^\top\mathbf{X}_c-\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P}-\mathbf{P}^\top\mathbf{X}_c^\top\mathbf{X}_c+\mathbf{P}^\top\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P}.\tag{4.2}
$$


ã“ã“ã§ $\mathbf{P}=\mathbf{W}\mathbf{W}^\top$ ã‹ã¤ $\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k$ ã‚ˆã‚Š

$$
\mathbf{P}^\top=\mathbf{P},\qquad
\mathbf{P}^2=\mathbf{P}
\tag{4.3}
$$

ãŒæˆã‚Šç«‹ã¤ï¼ˆå¯¾ç§°ã‹ã¤ã¹ãç­‰ï¼‰ã€‚
ã•ã‚‰ã«(4.3)ã¨ $\mathrm{tr}(AB)=\mathrm{tr}(BA)$ ã‚’ç”¨ã„ã‚‹ã¨ã€

$$
\mathrm{tr}(\mathbf{P}^\top\mathbf{X}_c^\top\mathbf{X}_c)=\mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P})
\tag{4.4}
$$

ã§ã‚ã‚‹ã€‚ã¾ãŸ (4.3) ã‚ˆã‚Š

$$
\mathrm{tr}(\mathbf{P}^\top\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P})=\mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P}^2)=\mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P}).
\tag{4.5}
$$

(4.1)ã€œ(4.5) ã‚’åˆã‚ã›ã‚‹ã¨

$$
\begin{aligned}
\|\mathbf{X}_c-\mathbf{X}_c\mathbf{P}\|_F^2&=
\mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c) - \mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P})-\mathrm{tr}(\mathbf{P}^\top\mathbf{X}_c^\top\mathbf{X}_c)+\mathrm{tr}(\mathbf{P}^\top\mathbf{X}_c^\top\mathbf{X}_c\mathbf{P})\\
&=\mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c)
-\mathrm{tr}(\mathbf{P}\mathbf{X}_c^\top\mathbf{X}_c).
\tag{4.6}
\end{aligned}
$$

$\mathbf{S}=\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c$ ã‚’ä»£å…¥ã—ã€

$$
\mathrm{tr}(\mathbf{P}\mathbf{X}_c^\top\mathbf{X}_c)
=N\mathrm{tr}(\mathbf{P}\mathbf{S})
=N\mathrm{tr}(\mathbf{W}\mathbf{W}^\top\mathbf{S})
=N\mathrm{tr}(\mathbf{W}^\top\mathbf{S}\mathbf{W})
\tag{4.7}
$$

ã‚ˆã‚Šã€

$$
\|\mathbf{X}_c-\mathbf{X}_c\mathbf{W}\mathbf{W}^\top\|_F^2=
\mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c)-N\mathrm{tr}(\mathbf{W}^\top\mathbf{S}\mathbf{W}).\tag{4.8}
$$

ã“ã“ã§ $\mathrm{tr}(\mathbf{X}_c^\top\mathbf{X}_c)$ ã¯ $\mathbf{W}$ ã«ä¾ã‚‰ãªã„å®šæ•°ãªã®ã§ã€(P1) ã®æœ€å°åŒ–ã¯

$$
\max_{\mathbf{W}}
\mathrm{tr}(\mathbf{W}^\top\mathbf{S}\mathbf{W})
\tag{4.9}
$$

ã¨ç­‰ä¾¡ã§ã‚ã‚Šã€ã“ã‚Œã¯ (P2) ã§ã‚ã‚‹ã€‚

---

### 5.å›ºæœ‰å€¤åˆ†è§£ã‚’ç”¨ã„ãŸè§£æ³•

$\mathbf{S}$ ã®å›ºæœ‰åˆ†è§£ (2.2) ã‚’ç”¨ã„ã‚‹ã€‚åˆ¶ç´„ $\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k$ ã®ä¸‹ã§

$$
\mathrm{tr}(\mathbf{W}^\top\mathbf{S}\mathbf{W})=
\mathrm{tr}(\mathbf{W}^\top\mathbf{Q}\boldsymbol{\Lambda}\mathbf{Q}^\top\mathbf{W}).
\tag{5.1}
$$

$\mathbf{Y}:=\mathbf{Q}^\top\mathbf{W}\in\mathbb{R}^{d\times k}$ ã¨ãŠãã¨ã€ $\mathbf{S}$ ãŒæ­£æ–¹è¡Œåˆ—ã§ã‚ã‚‹ãŸã‚ $\mathbf{Q}$ ã‚‚æ­£æ–¹è¡Œåˆ—ã§ã‚ã‚Šã€$\mathbf{Q}^\top\mathbf{Q}=\mathbf{I}$ ã§ã‚ã‚‹ãŸã‚ã€

$$
\mathbf{Y}^\top\mathbf{Y}=\mathbf{W}^\top\mathbf{Q}\mathbf{Q}^\top\mathbf{W}
=\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k,
\tag{5.2}
$$


ã‹ã¤ (5.1) ã¯

$$
\begin{aligned}
\mathrm{tr}(\mathbf{W}^\top\mathbf{S}\mathbf{W})
&=\mathrm{tr}(\mathbf{Y}^\top\boldsymbol{\Lambda}\mathbf{Y})\\
&=\sum_{m=1}^{k}\mathbf{y}_m^\top\boldsymbol{\lambda}\mathbf{y}_m \\
&=\sum_{m=1}^{k}\sum_{j=1}^{d}\lambda^\ast_j y_{j m}^2.
\tag{5.3}
\end{aligned}
$$

$\boldsymbol{\lambda}=\begin{pmatrix}\lambda_{1} & & 0 \\ & \ddots & \\ 0 & & \lambda_{d}\end{pmatrix}$ ã‚ˆã‚ŠçœŸã‚“ä¸­ã® $\boldsymbol{\lambda}$ ã‚’ã°ã‚‰ã—ã¦è¡Œåˆ—ã®æ›ã‘ç®—ã‚’è¶³ã—ç®—ã«æ›¸ãæ›ãˆã¦ã„ã‚‹ã€‚


ã“ã“ã§ $\sum_{j=1}^{d}y_{j m}^2=1$ï¼ˆå„åˆ—ãƒãƒ«ãƒ 1ï¼‰ã‹ã¤åˆ—ç›´äº¤ã®åˆ¶ç´„ãŒã‚ã‚‹ã€‚å›ºæœ‰å€¤ãŒé™é †ã§ã‚ã‚‹ã“ã¨ã‹ã‚‰ã€(5.3) ã¯é‡ã¿ $y_{jm}^2$ ã‚’å¤§ãã„å›ºæœ‰å€¤ã«é›†ä¸­ã•ã›ã‚‹ã»ã©å¤§ãããªã‚‹ã€‚æœ€å¤§å€¤ã¯

$$
\max\mathrm{tr}(\mathbf{W}^\top\mathbf{S}\mathbf{W})=\sum_{j=1}^{k}\lambda^\ast_j\tag{5.4}
$$

ã§é”æˆã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šæœ€åˆã® $k$ å€‹ã®å¤§ããªå›ºæœ‰å€¤ã‚’å…¨éƒ¨è¶³ã—ãŸã‚‚ã®ãŒã€å–ã‚Šå‡ºã›ã‚‹æƒ…å ±ã®æœ€å¤§é‡ã§ã‚ã‚‹ã€‚

ã“ã®ã¨ãã€ $\mathbf{Y}=\begin{pmatrix}\mathbf{I}_k\\\mathbf{0}\end{pmatrix}$ ã§ã‚ã‚Šã€ $\mathbf{Y}=\mathbf{Q}^\top\mathbf{W}$ ã®ä¸¡è¾ºã«å·¦ã‹ã‚‰ $\mathbf{Q}$ ã‚’ã‹ã‘ã‚‹ã¨ã€

$$
\begin{aligned}
\mathbf{W}&=\mathbf{Q}\mathbf{Y}\\
&=\left[\mathbf{q}_1, \mathbf{q}_2, \ldots, \mathbf{q}_d\right]\begin{pmatrix}\mathbf{I}_k\\\mathbf{0}\end{pmatrix}\\
&=[\mathbf{q}_1,\dots,\mathbf{q}_k]
\end{aligned}
$$

ã‚ˆã£ã¦ã€ $\mathbf{W}$ ã¯ å…±åˆ†æ•£è¡Œåˆ— $\mathbf{S}$ ã®ä¸Šä½ $k$ å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¸¦ã¹ãŸã‚‚ã®ã«ãªã‚‹ã€‚

ã¤ã¾ã‚ŠPCAã®æœ€é©åŒ–å•é¡Œã®è§£ã¯ $\mathbf{W}=\mathbf{Q}_k$ ã§ã‚ã‚‹ã€‚

---

### 6. SVDã‚’ç”¨ã„ãŸè§£æ³•

ä¸­å¿ƒåŒ–è¡Œåˆ— $\mathbf{X}_c$ ã® thin SVD ã‚’

$$
\mathbf{X}_c=\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^\top
\tag{6.1}
$$

ã¨ã™ã‚‹ã€‚
ã“ã®ã¨ãã€ $r$ ã‚’ $\mathbf{X}_c$ ã®ãƒ©ãƒ³ã‚¯ã¨ã™ã‚‹ã¨ã€
- $\mathbf{U}\in\mathbb{R}^{N\times r}$ : å·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«è¡Œåˆ—ã§ã‚ã‚Šã€ $\mathbf{U}^\top\mathbf{U}=\mathbf{I}_r$ ã‚’æº€ãŸã™ã€‚
- $\mathbf{\Sigma}\in\mathbb{R}^{r\times r}$ : ç‰¹ç•°å€¤è¡Œåˆ—ã€‚å¯¾è§’æˆåˆ†ã«ã¯æ­£ã®ç‰¹ç•°å€¤ $\sigma_1\geq\sigma_2\geq\cdots\geq\sigma_r>0$ ãŒé™é †ã«ä¸¦ã‚“ã§ã„ã‚‹ã€‚
- $\mathbf{V}\in\mathbb{R}^{d\times r}$ : å·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«è¡Œåˆ—ã§ã‚ã‚Šã€ $\mathbf{V}^\top\mathbf{V}=\mathbf{I}_r$ ã‚’æº€ãŸã™ã€‚ã“ã®åˆ—ãƒ™ã‚¯ãƒˆãƒ«ãŒPCAã«ãŠã‘ã‚‹ä¸»æˆåˆ†ã®æ–¹å‘ï¼ˆå›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã«å¯¾å¿œã™ã‚‹ã€‚


ã“ã‚Œã‚’ç”¨ã„ã¦å…±åˆ†æ•£ã‚’è¨ˆç®—ã™ã‚‹ã¨

$$
\begin{aligned}
\mathbf{S}&=\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c\\
&=\frac{1}{N}(\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^\top)^\top(\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^\top)\\
&=\frac{1}{N}\mathbf{V}\boldsymbol{\Sigma}\mathbf{U}^\top\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^\top\\
&=\frac{1}{N}\mathbf{V}\boldsymbol{\Sigma}^2\mathbf{V}^\top.
\end{aligned}
\tag{6.2}
$$

ã“ã®ä¸¡è¾ºã«å³å´ã‹ã‚‰ $\mathbf{V}$ ã‚’ã‹ã‘ã‚‹ã¨

$$
\begin{aligned}
\mathbf{S}\mathbf{V}&=\frac{1}{N}\mathbf{V}\boldsymbol{\Sigma}^2\mathbf{V}^\top\mathbf{V}\\
&=\mathbf{V}\left(\frac{1}{N}\boldsymbol{\Sigma}^2\right).
\end{aligned}
\tag{6.3}
$$

$\mathbf{V}$ ã®åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã®é•·ã•ã¯ 1 ã§ã‚ã‚‹ã‹ã‚‰ã€ $\mathbf{S}$ ã®å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã¯ $\mathbf{V}$ ã®åˆ—ã§ã‚ã‚Šã€å›ºæœ‰å€¤ã¯

$$
\lambda^\ast_m=\frac{\sigma_m^2}{N}
\qquad(m=1,\dots,r).
\tag{6.4}
$$

å›ºæœ‰å€¤ $\lambda^\ast_m$ ã¯ç‰¹ç•°å€¤ $\sigma_m$ ã®2ä¹—ã«æ¯”ä¾‹ã™ã‚‹ã€‚ç‰¹ç•°å€¤ãŒå¤§ãã„é †ã«ä¸¦ã‚“ã§ã„ã‚‹ã¨ã„ã†ã“ã¨ã¯ã€å›ºæœ‰å€¤ã‚‚è‡ªå‹•çš„ã«å¤§ãã„é †ã«ä¸¦ã‚“ã§ã„ã‚‹ã“ã¨ã«ãªã‚‹ã€‚

ã™ãªã‚ã¡ã€ $\mathbf{S}$ ã®å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ« $\mathbf{V}$ è¡Œåˆ—ã®å·¦ã‹ã‚‰ $k$ åˆ—ç›®ã¾ã§ã®ãƒ™ã‚¯ãƒˆãƒ« $[\mathbf{v}_1, \dots, \mathbf{v}_k]$ ã¯ã€ãã®ã¾ã¾ä¸Šä½ $k$ å€‹ã®å¤§ããªå›ºæœ‰å€¤ã«å¯¾å¿œã™ã‚‹å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾å¿œã™ã‚‹ã“ã¨ãŒåˆ†ã‚‹ã€‚

ã‚»ã‚¯ã‚·ãƒ§ãƒ³5ã®æœ€å¾Œã§ã€PCAã®æœ€é©è§£ $\mathbf{W}$ ã¯å…±åˆ†æ•£è¡Œåˆ— $\mathbf{S}$ ã®å›ºæœ‰å€¤ãŒå¤§ãã„é †ã«å¯¾å¿œã™ã‚‹å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’ $k$ æœ¬ä¸¦ã¹ãŸã‚‚ã®ã§ã‚ã‚‹ã¨ç¤ºã—ã¦ã„ã‚‹ãŸã‚ã€
ä¸Šä½ $k$ ä¸»æˆåˆ†æ–¹å‘ã¯

$$
\mathbf{W}=\mathbf{Q}_k=\mathbf{V}_k.
\tag{6.5}
$$

å…±åˆ†æ•£è¡Œåˆ—ã®å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ« $\mathbf{Q}$ ã¨å…ƒã®ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—ã®å³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ« $\mathbf{V}$ ãŒå®Œå…¨ã«ä¸€è‡´ã™ã‚‹ã€‚

**ã¤ã¾ã‚Šã€ç†è«–çš„ãªå®šç¾©ï¼ˆå›ºæœ‰å€¤åˆ†è§£ãƒ™ãƒ¼ã‚¹ï¼‰ã¨ã€å®Ÿç”¨çš„ãªè¨ˆç®—æ³•ï¼ˆSVDãƒ™ãƒ¼ã‚¹ï¼‰ãŒ $\mathbf{W}$ ã¨ã„ã†ä¸€ã¤ã®è§£ã‚’é€šã—ã¦ç¹‹ãŒã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚**ã€€ï¼ˆç¾ã—ã„ã­ï¼ï¼ï¼‰

> ã‚‚ã—ã€æ´»æ€§åŒ–é–¢æ•°ãªã—ã®ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆç·šå½¢å¤‰æ›ã®ã¿ï¼‰ã‚’ä½œã‚Šã€äºŒä¹—èª¤å·®ã‚’æœ€å°åŒ–ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã›ãŸã¨ã—ã¾ã™ã€‚å®Ÿã¯ã“ã®ã¨ãã€ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ä¸­é–“å±¤ï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼‰ãŒç²å¾—ã™ã‚‹ä½æ¬¡å…ƒã®éƒ¨åˆ†ç©ºé–“ã¯ã€PCAãŒå¼µã‚‹ä¸»æˆåˆ†ç©ºé–“ã¨æ•°å­¦çš„ã«å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ã“ã¨ãŒè¨¼æ˜ã•ã‚Œã¦ã„ã¾ã™ï¼ˆBaldi & Hornik, 1989ï¼‰ã€‚ã¤ã¾ã‚Šã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã€Œç·šå½¢ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚‚ã¨ã«æˆ»ã›ã€ã¨å‘½ä»¤ã™ã‚‹ã¨ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯å‹¾é…é™ä¸‹æ³•ã¨ã„ã†åŠ›æŠ€ã‚’ä½¿ã£ã¦ã€å…ˆã»ã©ç§ãŒå¿…æ­»ã«æ•°å¼ã§å°ã„ãŸ $\mathbf{W}$ ã¨åŒã˜æƒ…å ±ç©ºé–“ã‚’è‡ªåŠ›ã§è¦‹ã¤ã‘å‡ºã™ã®ã§ã™ã€‚

---

### 7. ã‚¹ã‚³ã‚¢ï¼ˆä½æ¬¡å…ƒè¡¨ç¾ï¼‰ã¨ãã®å±•é–‹

ã‚¹ã‚³ã‚¢ã‚’

$$
\mathbf{Z}:=\mathbf{X}_c\mathbf{W}
\in\mathbb{R}^{N\times k}
\tag{7.1}
$$

ã¨å®šç¾©ã™ã‚‹ã€‚ã•ã‚‰ã« $\mathbf{W}=\mathbf{V}_k$ ã¨ SVD (6.1) ã‚’ç”¨ã„ã¦å±•é–‹ã™ã‚‹ï¼š

$$
\mathbf{Z}
=\mathbf{X}_c\mathbf{V}_k
=(\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^\top)\mathbf{V}_k
=\mathbf{U}\boldsymbol{\Sigma}(\mathbf{V}^\top\mathbf{V}_k).
\tag{7.2}
$$

$\mathbf{V}=\left[\mathbf{V}_k\ \mathbf{V}_\perp\right]$ ã¨åˆ†å‰²ã™ã‚‹ã¨

$$
\mathbf{V}^\top\mathbf{V}_k=
\begin{bmatrix}
\mathbf{V}_k^\top\\
\mathbf{V}_\perp^\top
\end{bmatrix}\mathbf{V}_k=
\begin{bmatrix}
\mathbf{I}_k\\
\mathbf{0}
\end{bmatrix},
\tag{7.3}
$$

$\mathbf{V}$ ã®åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã¯ã™ã¹ã¦äº’ã„ã«ç›´äº¤ã—ã¦ã„ã¦ã€é•·ã•ãŒ1ã®æ­£è¦ç›´äº¤ç³»ã§ã‚ã‚‹ã€‚ã—ãŸãŒã£ã¦ã€
- $\mathbf{V}_k^\top \mathbf{V}_k=\mathbf{I}_k$ 
å‰åŠã‚°ãƒ«ãƒ¼ãƒ—åŒå£«ã®å†…ç©ã§ã‚ã‚‹ã€‚åŒã˜ãƒ™ã‚¯ãƒˆãƒ«åŒå£«ã®å†…ç©ï¼ˆé•·ã•ï¼‰ã¯ $1$ã€é•ã†ãƒ™ã‚¯ãƒˆãƒ«åŒå£«ã®å†…ç©ã¯ $0$ ã«ãªã‚‹ãŸã‚ã€å¯¾è§’æˆåˆ†ã ã‘ãŒ $1$ ã®å˜ä½è¡Œåˆ— $\mathbf{I}_k$ ã«ãªã‚‹ã€‚
- $\mathbf{V}_\perp^\top \mathbf{V}_k=\mathbf{0}$
ã€Œå¾ŒåŠã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ™ã‚¯ãƒˆãƒ«ã€ã¨ã€Œå‰åŠã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ™ã‚¯ãƒˆãƒ«ã€ã®å†…ç©ã‚’è¨ˆç®—ã™ã‚‹ã€‚SVDã®æ€§è³ªä¸Šã€ç•°ãªã‚‹åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã¯ä¾‹å¤–ãªãã™ã¹ã¦ç›´äº¤ã—ã¦ã„ã‚‹ï¼ˆ$\mathbf{v}_i^\top \mathbf{v}_j = 0 \quad (i \neq j)$ï¼‰ãŸã‚ã€ã©ã®çµ„ã¿åˆã‚ã›ã§å†…ç©ã‚’ã¨ã£ã¦ã‚‚å¿…ãš $0$ ã«ãªã‚‹ã€‚
çµæœã¨ã—ã¦ã€æˆåˆ†ãŒã™ã¹ã¦ $0$ ã®ã‚¼ãƒ­è¡Œåˆ— $\mathbf{0}$ ã«ãªã‚‹ã€‚

ã‚ˆã£ã¦

$$
\mathbf{Z}=
\mathbf{U}\boldsymbol{\Sigma}
\begin{bmatrix}
\mathbf{I}_k\\
\mathbf{0}
\end{bmatrix}=
\mathbf{U}_k\boldsymbol{\Sigma}_k.
\tag{7.4}
$$

---

### 8. èª¬æ˜åˆ†æ•£ãƒ»èª¬æ˜åˆ†æ•£æ¯”

ç¬¬ $m$ ä¸»æˆåˆ†ã‚¹ã‚³ã‚¢åˆ—ã‚’ $\mathbf{z}_m:=\mathbf{Z}_{[:,m]}$ ã¨ã™ã‚‹ã€‚
ï¼ˆåˆ†æ¯ $N$ ã®ï¼‰åˆ†æ•£ã‚’

$$
\mathrm{Var}_N(\mathbf{z}_m)
:=
\frac{1}{N}\|\mathbf{z}_m\|_2^2
\tag{8.1}
$$

ã¨å®šç¾©ã™ã‚‹ã€‚

(7.4) ã‚ˆã‚Š $\mathbf{z}_m=\sigma_m\mathbf{u}_m$ ( $\|\mathbf{u}_m\|_2=1$ )ãªã®ã§ã€

$$
\mathrm{Var}_N(\mathbf{z}_m)=
\frac{1}{N}|\sigma_m\mathbf{u}_m|_2^2=
\frac{1}{N}\sigma_m^2.
\tag{8.2}
$$

ã“ã“ã§

$$
\lambda_m:=\frac{\sigma_m^2}{N}
\tag{8.3}
$$

ã‚’ç¬¬ $m$ ä¸»æˆåˆ†ã®èª¬æ˜åˆ†æ•£ã¨å‘¼ã¶ã€‚
ã¾ãŸã€èª¬æ˜åˆ†æ•£æ¯”ã‚’ä¿æŒã—ãŸ $k$ æˆåˆ†å†…ã§æ­£è¦åŒ–ã—ã¦

$$
\mathrm{EVR}_m:=\frac{\lambda_m}{\sum_{j=1}^{k}\lambda_j}
\tag{8.4}
$$

ã¨å®šç¾©ã™ã‚‹ã€‚( $N$ ã¯ç´„åˆ†ã§ãã‚‹ã®ã§)

$$
\mathrm{EVR}_m=
\frac{\sigma_m^2}{\sum_{j=1}^k\sigma_j^2}.
\tag{8.5}
$$

---

### 9. ç™½è‰²åŒ–ï¼ˆwhiteningï¼‰

ç™½è‰²åŒ–ã¯å„ä¸»æˆåˆ†ã‚’åˆ†æ•£1ã«æ­£è¦åŒ–ã™ã‚‹æ“ä½œã§ã‚ã‚‹ã€‚ç™½è‰²åŒ–ã‚¹ã‚³ã‚¢ã‚’

$$
\mathbf{Z}^{\mathrm{white}}:=
\mathbf{Z}\mathrm{diag}(\lambda_1^{-1/2},\dots,\lambda_k^{-1/2})
\tag{9.1}
$$

ã§å®šç¾©ã™ã‚‹ã€‚åˆ—ã”ã¨ã«ã¯

$$
\mathbf{z}_{m}^\mathrm{white}=
\frac{\mathbf{z}_m}{\sqrt{\lambda_m}}.
\tag{9.2}
$$

åˆ†æ•£ã‚’ç¢ºã‹ã‚ã‚‹ã€‚(8.1)~(8.3)ã‚ˆã‚Šã€

$$
\mathrm{Var}_N(\mathbf{z}_m^\mathrm{white})=
\frac{1}{N}\left\|\frac{\mathbf{z}_m}{\sqrt{\lambda_m}}\right\|_2^2=
\frac{1}{N}\frac{\|\mathbf{z}_m\|_2^2}{\lambda_m}=
\frac{1}{N}\frac{|\mathbf{z}_m|_2^2}{(1/N)\|\mathbf{z}_m\|_2^2}=
1.
\tag{9.3}
$$

å¾“ã£ã¦ç™½è‰²åŒ–å¾Œã€å„ä¸»æˆåˆ†ã¯åˆ†æ•£ 1 ã‚’æŒã¤ã€‚

---

## PCAã® Pytorch å®Ÿè£…ï¼ˆGPUå¯¾å¿œï¼‰

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

#### 1. ç›®çš„

2æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ« `X (N, d)` ã‚’ **SVDãƒ™ãƒ¼ã‚¹PCA**ã§ `k=n_components` æ¬¡å…ƒã¸å°„å½±ã—ã€

* ä¸»æˆåˆ†æ–¹å‘ï¼ˆloadingsï¼‰
* ä¸»æˆåˆ†å¾—ç‚¹ï¼ˆscoresï¼‰
* åˆ†æ•£ãƒ»å¯„ä¸ç‡

ã‚’å–å¾—ã™ã‚‹ã€‚
ã“ã®å®Ÿè£…ã¯ `torch.linalg.svd` ã‚’ç”¨ã„ã‚‹ãŸã‚ã€**GPUãƒ†ãƒ³ã‚½ãƒ«ã‚’æ¸¡ã›ã°GPUä¸Šã§è¨ˆç®—**ã•ã‚Œã‚‹ã€‚


#### 2. åŸºæœ¬ä½¿ç”¨ä¾‹ï¼ˆfit â†’ transformï¼‰

ä»¥ä¸‹ã§å®Ÿè£…ã—ãŸ pca.py ã‚’åŒéšå±¤ã«ç½®ãå‰æï¼š

```python
import torch
from pca import PCA

# ä¾‹: GPU
device = "cuda" if torch.cuda.is_available() else "cpu"

X = torch.randn(1000, 256, device=device)

pca = PCA(n_components=32, center=True, whiten=False)
pca.fit(X)

Z = pca.transform(X)          # (1000, 32)
W = pca.loadings              # (256, 32)  ä¸»è»¸ï¼ˆV_kï¼‰
mu = pca.mean                 # (256,)     å¹³å‡
ev = pca.explained_variance_  # (32,)      Î»_i = Ïƒ_i^2 / N
```

* `center=True` ã®ã¨ã `X` ã‚’ç‰¹å¾´é‡å¹³å‡ã§ä¸­å¿ƒåŒ–ã—ã¦ã‹ã‚‰PCAã™ã‚‹ã€‚
* `loadings`ï¼ˆ= `loadings_`ï¼‰ã¯ `(d,k)` ã®åˆ—æ­£è¦ç›´äº¤ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ`V_k`ï¼‰ã€‚
* `Z = (X - mean) @ loadings` ãŒ transform ã®ä¸­èº«ã€‚

#### 3. fit_transformï¼ˆã¾ã¨ã‚ã¦å®Ÿè¡Œï¼‰

```python
Z = PCA(n_components=32).fit_transform(X)
```

`fit()` ã®å¾Œã«åŒã˜ `X` ã‚’ `transform()` ã™ã‚‹ã ã‘ã€‚

#### 4. whiteningï¼ˆä»»æ„ï¼‰

`whiten=True` ã«ã™ã‚‹ã¨ã€transformå¾Œã«å„æˆåˆ†ã‚’ `sqrt(explained_variance_)` ã§å‰²ã‚‹ï¼š

```python
pca = PCA(n_components=32, whiten=True).fit(X)
Z_white = pca.transform(X)
```

#### 5. ä¿å­˜ã¨å¾©å…ƒï¼ˆsave / loadï¼‰

- **ä¿å­˜**

```python
pca.save("pca.pt")
```

- **èª­ã¿è¾¼ã¿ï¼ˆCPUã¸ï¼‰**

```python
pca2 = PCA.load("pca.pt", map_location="cpu")
```

- **èª­ã¿è¾¼ã¿ï¼ˆGPUã¸æ˜ç¤ºçš„ã«ç§»ã™ï¼‰**

```python
pca2 = PCA.load("pca.pt", map_location="cpu", device="cuda")
```

* `save()` ã¯å­¦ç¿’æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’CPUã¸è½ã¨ã—ã¦ `.pt` ã«ä¿å­˜ã™ã‚‹ã€‚
* `load()` ã¯ `map_location` ã§èª­ã¿è¾¼ã¿ä½ç½®ã‚’æ±ºã‚ã€`device` æŒ‡å®šãŒã‚ã‚Œã°æœ€çµ‚çš„ã«ãã“ã¸ç§»ã™ï¼ˆå„ªå…ˆï¼‰ã€‚

#### 6. ä¸»è¦å±æ€§ï¼ˆå­¦ç¿’å¾Œã«å‚ç…§å¯èƒ½ï¼‰

å­¦ç¿’å¾Œã€ä»¥ä¸‹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ï¼š

* `pca.mean_` / `pca.mean`ï¼šç‰¹å¾´é‡å¹³å‡ `(d,)`
* `pca.loadings_` / `pca.loadings`ï¼šä¸»è»¸ `(d,k)`
* `pca.components_`ï¼š`loadings_` ã®åˆ¥åï¼ˆsklearnäº’æ›ï¼‰
* `pca.singular_values_`ï¼šç‰¹ç•°å€¤ `(k,)`
* `pca.explained_variance_`ï¼šåˆ†æ•£ `(k,)`ï¼ˆã“ã®å®Ÿè£…ã¯ **Ïƒ^2 / N**ï¼‰
* `pca.explained_variance_ratio_`ï¼šå¯„ä¸ç‡ `(k,)`ï¼ˆ**ä¸Šä½kæˆåˆ†å†…ã§æ­£è¦åŒ–**ï¼‰
* `pca.n_samples_`ï¼šå­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°
* `pca.fitted_`ï¼šå­¦ç¿’æ¸ˆã¿ãƒ•ãƒ©ã‚°

#### 7. å…¥åŠ›åˆ¶ç´„ï¼ˆFail Fastï¼‰

* `X` ã¯ **torch.Tensor ã‹ã¤ float**ï¼ˆæ•´æ•°ã¯ä¸å¯ï¼‰
* `X.ndim == 2`ï¼ˆå½¢çŠ¶ã¯ `(N, d)`ï¼‰
* `transform()` ã® `d` ã¯ fitæ™‚ã¨ä¸€è‡´å¿…é ˆ
  ã“ã‚Œã‚‰ã«é•åã™ã‚‹ã¨ `TypeError` / `ValueError` ã§å³è½ã¡ã‚‹ã€‚

---

### å®Ÿè£…

```python
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Optional, TypeAlias, Union

import torch

Tensor: TypeAlias = torch.Tensor
PathLike: TypeAlias = Union[str, Path]

__all__ = ["PCA"]


def _as_tensor_2d(x: Any, *, dtype: Optional[torch.dtype], device: Optional[torch.device]) -> Tensor:
    """å…¥åŠ›ã‚’2æ¬¡å…ƒfloat Tensorã¨ã—ã¦æ¤œè¨¼ãƒ»æ•´å½¢ã™ã‚‹ï¼ˆFail Fastï¼‰ã€‚

    Parameters
    ----------
    x : Any
        å…¥åŠ›ã€‚torch.Tensor ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
    dtype : torch.dtype, optional
        æŒ‡å®šæ™‚ã€dtype ã«å¤‰æ›ã™ã‚‹ã€‚
    device : torch.device, optional
        æŒ‡å®šæ™‚ã€device ã«ç§»å‹•ã™ã‚‹ã€‚

    Returns
    -------
    X : torch.Tensor
        å½¢çŠ¶ (N, d) ã®2æ¬¡å…ƒæµ®å‹•å°æ•°ç‚¹ãƒ†ãƒ³ã‚½ãƒ«ã€‚

    Raises
    ------
    TypeError
        x ãŒ torch.Tensor ã§ãªã„ã€ã¾ãŸã¯æµ®å‹•å°æ•°ç‚¹ã§ãªã„å ´åˆã€‚
    ValueError
        x ãŒ2æ¬¡å…ƒã§ãªã„ã€ã¾ãŸã¯ç©ºã®å ´åˆã€‚
    """
    if not isinstance(x, torch.Tensor):
        raise TypeError(f"X ã¯ torch.Tensor ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {type(x)}")
    if x.ndim != 2:
        raise ValueError(f"X ã¯2æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ« (N, d) ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: shape={tuple(x.shape)}")
    if x.numel() == 0:
        raise ValueError("X ã¯ç©ºã§ã‚ã£ã¦ã¯ãªã‚Šã¾ã›ã‚“ã€‚")
    if not x.is_floating_point():
        raise TypeError(f"X ã¯æµ®å‹•å°æ•°ç‚¹ãƒ†ãƒ³ã‚½ãƒ«ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: dtype={x.dtype}")

    if dtype is not None and x.dtype != dtype:
        x = x.to(dtype=dtype)
    if device is not None and x.device != device:
        x = x.to(device=device)
    return x


def _safe_div(a: Tensor, b: Tensor, eps: float) -> Tensor:
    """ã‚¼ãƒ­å‰²ã‚’é¿ã‘ãŸå®‰å…¨ãªé™¤ç®— a / max(b, eps)ã€‚"""
    return a / b.clamp_min(eps)


class PCA:
    r"""PyTorchå®Ÿè£…ã®PCAï¼ˆSVDãƒ™ãƒ¼ã‚¹ã€GPUå¯¾å¿œï¼‰ã€‚

    æœ¬ã‚¯ãƒ©ã‚¹ã¯æ¬¡ã®å®šå¼åŒ–ã«å³å¯†ã«å¾“ã†ã€‚

    **ä¸­å¿ƒåŒ–**
    - å…¥åŠ›è¡Œåˆ—ã‚’ :math:`\mathbf{X}\in\mathbb{R}^{N\times d}` ã¨ã™ã‚‹ã€‚
    - ç‰¹å¾´é‡å¹³å‡ :math:`\boldsymbol{\mu}\in\mathbb{R}^{d}` ã‚’ç”¨ã„ã¦
      :math:`\mathbf{X}_c = \mathbf{X} - \mathbf{1}\boldsymbol{\mu}^{\top}` ã¨ã™ã‚‹ã€‚

    **ï¼ˆæ‰“ã¡åˆ‡ã‚Šï¼‰SVD**
    - :math:`\mathbf{X}_c \approx \mathbf{U}_k \boldsymbol{\Sigma}_k \mathbf{V}_k^{\top}`

    **ä¸»è»¸ï¼ˆloadingsï¼‰ã¨ã‚¹ã‚³ã‚¢ï¼ˆscoresï¼‰**
    - loadingsï¼ˆä¸»æˆåˆ†æ–¹å‘ï¼‰: :math:`\mathbf{W}=\mathbf{V}_k \in \mathbb{R}^{d\times k}`
    - scoresï¼ˆä¸»æˆåˆ†å¾—ç‚¹ï¼‰: :math:`\mathbf{Z}=\mathbf{X}_c\mathbf{W}\in\mathbb{R}^{N\times k}`

    Parameters
    ----------
    n_components : int
        ä¸»æˆåˆ†æ•° :math:`k`ã€‚
    center : bool, default=True
        True ã®å ´åˆã€ç‰¹å¾´é‡å¹³å‡ã‚’å¼•ã„ã¦ã‹ã‚‰SVDã‚’è¡Œã†ã€‚
    whiten : bool, default=False
        True ã®å ´åˆã€transform å‡ºåŠ› :math:`\mathbf{Z}` ã‚’
        :math:`\sqrt{\lambda_i}`ï¼ˆæˆåˆ†åˆ†æ•£ï¼‰ã§å‰²ã‚Šã€å„æˆåˆ†ã‚’å˜ä½åˆ†æ•£åŒ–ã™ã‚‹ã€‚
    eps : float, default=1e-12
        æ•°å€¤å®‰å®šåŒ–ï¼ˆã‚¼ãƒ­å‰²å›é¿ï¼‰ç”¨ã®å°ã•ã„å®šæ•°ã€‚
    dtype : torch.dtype, optional
        fit/transform æ™‚ã«å†…éƒ¨ã§ã“ã®dtypeã¸æƒãˆã‚‹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¥åŠ›ã«å¾“ã†ï¼‰ã€‚
    device : str | torch.device, optional
        fit/transform æ™‚ã«å†…éƒ¨ã§ã“ã®deviceã¸æƒãˆã‚‹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¥åŠ›ã«å¾“ã†ï¼‰ã€‚

    Attributes
    ----------
    mean_ : torch.Tensor
        ç‰¹å¾´é‡å¹³å‡ :math:`\boldsymbol{\mu}`ã€‚å½¢çŠ¶ (d,)ã€‚
        center=False ã®å ´åˆã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã€‚
    loadings_ : torch.Tensor
        loadingsï¼ˆä¸»è»¸ï¼‰: :math:`\mathbf{W}`ã€‚å½¢çŠ¶ (d, k)ã€‚
        å„åˆ—ã¯ç›´äº¤è¦æ ¼åŒ–ã•ã‚Œã‚‹ã€‚
    components_ : torch.Tensor
        sklearnäº’æ›ã®åˆ¥åã€‚loadings_ ã¨åŒä¸€å‚ç…§ã€‚
    singular_values_ : torch.Tensor
        ç‰¹ç•°å€¤ :math:`(\sigma_1,\ldots,\sigma_k)`ã€‚å½¢çŠ¶ (k,)ã€‚
    explained_variance_ : torch.Tensor
        å„æˆåˆ†ã®åˆ†æ•£ :math:`\lambda_i`ã€‚å½¢çŠ¶ (k,)ã€‚
        æœ¬å®Ÿè£…ã§ã¯ **åˆ†æ¯N** ã®æµå„€ã§ :math:`\lambda_i=\sigma_i^2 / N` ã‚’æ¡ç”¨ã™ã‚‹ã€‚
    explained_variance_ratio_ : torch.Tensor
        ä¿æŒã—ãŸkæˆåˆ†å†…ã§æ­£è¦åŒ–ã—ãŸå¯„ä¸ç‡ã€‚
        :math:`\lambda_i / \sum_{j=1}^{k}\lambda_j`ã€‚å½¢çŠ¶ (k,)ã€‚
    n_samples_ : int
        fit ã«ç”¨ã„ãŸã‚µãƒ³ãƒ—ãƒ«æ•° :math:`N`ã€‚
    fitted_ : bool
        å­¦ç¿’æ¸ˆã¿ãƒ•ãƒ©ã‚°ã€‚

    Notes
    -----
    - SVDã¯ `torch.linalg.svd(Xc, full_matrices=False)` ã‚’ç”¨ã„ã‚‹ã€‚
      ã“ã‚Œã¯å³å¯†ã ãŒã€å¤§è¦æ¨¡ (N,dãŒéå¸¸ã«å¤§ãã„) ã§ã¯ãƒ¡ãƒ¢ãƒª/è¨ˆç®—ãŒé‡ã„ã€‚
    - explained_variance_ratio_ ã¯ã€Œä¸Šä½kå†…ã§ã®æ­£è¦åŒ–ã€ã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚
      å…¨æˆåˆ†ï¼ˆrankå…¨ä½“ï¼‰ã§ã®EVRãŒå¿…è¦ãªã‚‰å…¨ç‰¹ç•°å€¤ãŒå¿…è¦ã€‚
    - PyTorch 2.6 ä»¥é™ã§ã¯ `torch.load` ã® `weights_only` ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãŒ True ã«ãªã£ãŸã€‚
      æœ¬å®Ÿè£…ã¯ checkpoint ã‚’ã€ŒTensor + ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã®ã¿ã€ã®è¾æ›¸ã¨ã—ã¦ä¿å­˜ã—ã€
      `weights_only=True` ã§å®‰å…¨ã«ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹å½¢å¼ã«ã—ã¦ã„ã‚‹ã€‚

    Raises
    ------
    ValueError
        å…¥åŠ›shapeä¸æ­£ã€n_componentsãŒç¯„å›²å¤–ãªã©ã€‚
    TypeError
        å…¥åŠ›ãŒtorch.Tensorã§ãªã„ã€ã¾ãŸã¯æµ®å‹•å°æ•°ç‚¹ã§ãªã„å ´åˆã€‚

    Examples
    --------
    >>> import torch
    >>> from decomposition.pca import PCA
    >>> X = torch.randn(1000, 256, device="cuda")
    >>> pca = PCA(n_components=32).fit(X)
    >>> Z = pca.transform(X)
    >>> pca.save("pca.pt")
    >>> pca2 = PCA.load("pca.pt", map_location="cpu")
    """

    def __init__(
        self,
        n_components: int,
        *,
        center: bool = True,
        whiten: bool = False,
        eps: float = 1e-12,
        dtype: Optional[torch.dtype] = None,
        device: Optional[Union[str, torch.device]] = None,
    ) -> None:
        if not isinstance(n_components, int) or n_components <= 0:
            raise ValueError(f"n_components ã¯æ­£ã®intã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {n_components}")
        if not isinstance(center, bool):
            raise TypeError("center ã¯ bool ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        if not isinstance(whiten, bool):
            raise TypeError("whiten ã¯ bool ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        if not isinstance(eps, (float, int)) or float(eps) <= 0.0:
            raise ValueError(f"eps ã¯æ­£ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {eps}")

        self.n_components: int = n_components
        self.center: bool = center
        self.whiten: bool = whiten
        self.eps: float = float(eps)

        self._dtype: Optional[torch.dtype] = dtype
        self._device: Optional[torch.device] = torch.device(device) if device is not None else None

        self.mean_: Optional[Tensor] = None
        self.loadings_: Optional[Tensor] = None
        self.components_: Optional[Tensor] = None
        self.singular_values_: Optional[Tensor] = None
        self.explained_variance_: Optional[Tensor] = None
        self.explained_variance_ratio_: Optional[Tensor] = None
        self.n_samples_: Optional[int] = None
        self.fitted_: bool = False

    @property
    def loadings(self) -> Tensor:
        """loadings_ï¼ˆä¸»è»¸ï¼‰ã¸ã®åˆ¥åã‚¢ã‚¯ã‚»ã‚¹ã€‚"""
        if not self.fitted_ or self.loadings_ is None:
            raise RuntimeError("PCAã¯æœªå­¦ç¿’ã§ã™ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        return self.loadings_

    @property
    def mean(self) -> Tensor:
        """mean_ï¼ˆç‰¹å¾´é‡å¹³å‡ï¼‰ã¸ã®åˆ¥åã‚¢ã‚¯ã‚»ã‚¹ã€‚"""
        if not self.fitted_ or self.mean_ is None:
            raise RuntimeError("PCAã¯æœªå­¦ç¿’ã§ã™ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        return self.mean_

    def fit(self, X: Tensor) -> "PCA":
        """PCAã‚’å­¦ç¿’ã™ã‚‹ï¼ˆä¸­å¿ƒåŒ–â†’SVDï¼‰ã€‚

        Parameters
        ----------
        X : torch.Tensor
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚å½¢çŠ¶ (N, d) ã®æµ®å‹•å°æ•°ç‚¹ãƒ†ãƒ³ã‚½ãƒ«ã€‚

        Returns
        -------
        self : PCA
            å­¦ç¿’æ¸ˆã¿ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚

        Raises
        ------
        ValueError
            n_components ãŒ min(N, d) ã‚’è¶…ãˆã‚‹å ´åˆãªã©ã€‚
        TypeError
            å…¥åŠ›ãŒtorch.Tensorã§ãªã„ã€ã¾ãŸã¯æµ®å‹•å°æ•°ç‚¹ã§ãªã„å ´åˆã€‚
        """
        X = _as_tensor_2d(X, dtype=self._dtype, device=self._device)
        n, d = int(X.shape[0]), int(X.shape[1])

        k = self.n_components
        if k > min(n, d):
            raise ValueError(f"n_components={k} ã¯ min(N,d)={min(n, d)} ä»¥ä¸‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

        if self.center:
            mean = X.mean(dim=0)
            Xc = X - mean
        else:
            mean = torch.zeros(d, dtype=X.dtype, device=X.device)
            Xc = X

        # Xc = U S Vh
        _, S, Vh = torch.linalg.svd(Xc, full_matrices=False)

        S_k = S[:k]
        V_k = Vh[:k, :].T.contiguous()  # (d, k)

        explained_var = (S_k * S_k) / float(n)  # lambda_i = sigma_i^2 / N
        evr = _safe_div(explained_var, explained_var.sum(), eps=self.eps)

        self.mean_ = mean
        self.loadings_ = V_k
        self.components_ = self.loadings_
        self.singular_values_ = S_k
        self.explained_variance_ = explained_var
        self.explained_variance_ratio_ = evr
        self.n_samples_ = n
        self.fitted_ = True
        return self

    def transform(self, X: Tensor) -> Tensor:
        """å­¦ç¿’æ¸ˆã¿PCAç©ºé–“ã¸å°„å½±ã™ã‚‹ã€‚

        Parameters
        ----------
        X : torch.Tensor
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚å½¢çŠ¶ (N, d)ã€‚

        Returns
        -------
        Z : torch.Tensor
            ä¸»æˆåˆ†å¾—ç‚¹ã€‚å½¢çŠ¶ (N, k)ã€‚
            whiten=True ã®å ´åˆã€å„åˆ—ã‚’ sqrt(explained_variance_) ã§å‰²ã‚‹ã€‚

        Raises
        ------
        RuntimeError
            æœªå­¦ç¿’ã®å ´åˆã€‚
        ValueError
            å…¥åŠ›ã®æ¬¡å…ƒ d ãŒå­¦ç¿’æ™‚ã¨ä¸€è‡´ã—ãªã„å ´åˆã€‚
        """
        if not self.fitted_:
            raise RuntimeError("PCAã¯æœªå­¦ç¿’ã§ã™ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        assert self.mean_ is not None
        assert self.loadings_ is not None
        assert self.explained_variance_ is not None

        X = _as_tensor_2d(X, dtype=self.mean_.dtype, device=self.mean_.device)
        if int(X.shape[1]) != int(self.mean_.shape[0]):
            raise ValueError(
                f"å…¥åŠ›d={int(X.shape[1])}ãŒå­¦ç¿’æ™‚d={int(self.mean_.shape[0])}ã¨ä¸€è‡´ã—ã¾ã›ã‚“ã€‚"
            )

        Xc = X - self.mean_ if self.center else X
        Z = Xc @ self.loadings_

        if self.whiten:
            Z = _safe_div(Z, torch.sqrt(self.explained_variance_), eps=self.eps)
        return Z

    def fit_transform(self, X: Tensor) -> Tensor:
        """å­¦ç¿’ã¨å¤‰æ›ã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œã™ã‚‹ã€‚"""
        self.fit(X)
        return self.transform(X)

    def _state_dict(self) -> Dict[str, Any]:
        """å­¦ç¿’æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã€ŒTensor + ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã®ã¿ã€ã®è¾æ›¸ã¨ã—ã¦è¿”ã™ã€‚

        Notes
        -----
        PyTorch 2.6 ä»¥é™ã§ã¯ `torch.load(..., weights_only=True)` ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãªã‚Šã€
        ä»»æ„ã®ã‚¯ãƒ©ã‚¹ï¼ˆdataclass ç­‰ï¼‰ã‚’å«ã‚€pickleã®å¾©å…ƒãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã‚‹ã€‚
        ãã®ãŸã‚ã€æœ¬å®Ÿè£…ã§ã¯ checkpoint å†…ã«ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å«ã‚ãªã„ã€‚
        """
        if not self.fitted_:
            raise RuntimeError("æœªå­¦ç¿’ã®ãŸã‚ä¿å­˜ã§ãã¾ã›ã‚“ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        assert self.mean_ is not None
        assert self.loadings_ is not None
        assert self.singular_values_ is not None
        assert self.explained_variance_ is not None
        assert self.explained_variance_ratio_ is not None
        assert self.n_samples_ is not None

        state: Dict[str, Any] = {
            "format_version": 1,
            "n_components": int(self.n_components),
            "center": bool(self.center),
            "whiten": bool(self.whiten),
            "eps": float(self.eps),
            "mean": self.mean_.detach().cpu(),
            "loadings": self.loadings_.detach().cpu(),
            "singular_values": self.singular_values_.detach().cpu(),
            "explained_variance": self.explained_variance_.detach().cpu(),
            "explained_variance_ratio": self.explained_variance_ratio_.detach().cpu(),
            "n_samples": int(self.n_samples_),
            "dtype": str(self.mean_.dtype),
            "device": str(self.mean_.device),
        }
        return {"pca_state": state}

    def save(self, path: PathLike) -> None:
        """å­¦ç¿’æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã€‚

        Parameters
        ----------
        path : str | pathlib.Path
            ä¿å­˜å…ˆãƒ‘ã‚¹ï¼ˆä¾‹: "pca.pt"ï¼‰ã€‚

        Raises
        ------
        RuntimeError
            æœªå­¦ç¿’ã®å ´åˆã€‚
        """
        p = Path(path)
        p.parent.mkdir(parents=True, exist_ok=True)
        torch.save(self._state_dict(), p)

    @classmethod
    def load(
        cls,
        path: PathLike,
        *,
        map_location: Optional[Union[str, torch.device]] = None,
        device: Optional[Union[str, torch.device]] = None,
        dtype: Optional[torch.dtype] = None,
    ) -> "PCA":
        """ä¿å­˜æ¸ˆã¿PCAã‚’èª­ã¿è¾¼ã‚€ã€‚

        Parameters
        ----------
        path : str | pathlib.Path
            save() ã§ä¿å­˜ã—ãŸ .pt ã¸ã®ãƒ‘ã‚¹ã€‚
        map_location : str | torch.device, optional
            torch.load ã«æ¸¡ã™ map_locationï¼ˆä¾‹: "cpu" / "cuda"ï¼‰ã€‚
        device : str | torch.device, optional
            èª­ã¿è¾¼ã¿å¾Œã«æ˜ç¤ºçš„ã«ç§»ã™deviceã€‚æŒ‡å®šã—ãŸå ´åˆ map_location ã‚ˆã‚Šå„ªå…ˆã€‚
        dtype : torch.dtype, optional
            èª­ã¿è¾¼ã¿å¾Œã«ã“ã®dtypeã¸ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹ã€‚

        Returns
        -------
        pca : PCA
            å¾©å…ƒã•ã‚ŒãŸPCAã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚

        Raises
        ------
        FileNotFoundError
            path ãŒå­˜åœ¨ã—ãªã„å ´åˆã€‚
        ValueError
            ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ãªå ´åˆã€‚
        """
        p = Path(path)
        if not p.exists():
            raise FileNotFoundError(str(p))

        # PyTorch 2.6+ ã¯ weights_only=True ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå®‰å…¨å´ï¼‰ã€‚
        # æœ¬å®Ÿè£…ã¯ dict-only å½¢å¼ã®ãŸã‚ weights_only=True ã§èª­ã¿è¾¼ã‚€ã€‚
        try:
            payload = torch.load(p, map_location=map_location, weights_only=True)
        except TypeError:
            # å¤ã„PyTorchã§ã¯ weights_only å¼•æ•°ãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹
            payload = torch.load(p, map_location=map_location)

        if not isinstance(payload, dict) or "pca_state" not in payload:
            raise ValueError("PCAãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆ'pca_state' ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

        state = payload["pca_state"]
        if not isinstance(state, dict):
            raise ValueError("PCAãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆpca_state ãŒ dict ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

        required_keys = (
            "n_components",
            "center",
            "whiten",
            "eps",
            "mean",
            "loadings",
            "singular_values",
            "explained_variance",
            "explained_variance_ratio",
            "n_samples",
        )
        missing = [k for k in required_keys if k not in state]
        if missing:
            raise ValueError(f"PCAãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆæ¬ æã‚­ãƒ¼: {missing}ï¼‰ã€‚")

        pca = cls(
            n_components=int(state["n_components"]),
            center=bool(state["center"]),
            whiten=bool(state["whiten"]),
            eps=float(state["eps"]),
            dtype=dtype,
            device=torch.device(device) if device is not None else None,
        )

        tgt_device: Optional[torch.device]
        if device is not None:
            tgt_device = torch.device(device)
        elif map_location is not None:
            tgt_device = torch.device(map_location)
        else:
            tgt_device = None

        mean = state["mean"]
        loadings = state["loadings"]
        sv = state["singular_values"]
        ev = state["explained_variance"]
        evr = state["explained_variance_ratio"]

        if not isinstance(mean, torch.Tensor) or not isinstance(loadings, torch.Tensor):
            raise ValueError("PCAãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆãƒ†ãƒ³ã‚½ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

        if dtype is not None:
            mean = mean.to(dtype=dtype)
            loadings = loadings.to(dtype=dtype)
            sv = sv.to(dtype=dtype)
            ev = ev.to(dtype=dtype)
            evr = evr.to(dtype=dtype)

        if tgt_device is not None:
            mean = mean.to(device=tgt_device)
            loadings = loadings.to(device=tgt_device)
            sv = sv.to(device=tgt_device)
            ev = ev.to(device=tgt_device)
            evr = evr.to(device=tgt_device)

        pca.mean_ = mean
        pca.loadings_ = loadings
        pca.components_ = pca.loadings_
        pca.singular_values_ = sv
        pca.explained_variance_ = ev
        pca.explained_variance_ratio_ = evr
        pca.n_samples_ = int(state["n_samples"])
        pca.fitted_ = True
        return pca
```