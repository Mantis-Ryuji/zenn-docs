---
title: "PCAã®æ•°ç†è§£èª¬ã¨å®Ÿè£…(PyTorch)"
emoji: "ğŸ"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["AI", "æ©Ÿæ¢°å­¦ç¿’", "ç·šå½¢ä»£æ•°", "Python", "PyTorch"]
published: false
---

## ä¸»æˆåˆ†åˆ†æã®æ•°ç†è§£èª¬ï¼ˆSVDï¼‰

### 1. å‰æ

ã‚µãƒ³ãƒ—ãƒ«æ•° $N\in\mathbb{N}$ã€ç‰¹å¾´æ¬¡å…ƒ $d\in\mathbb{N}$ ã®ãƒ‡ãƒ¼ã‚¿è¡Œåˆ— $\mathbf{X}\in\mathbb{R}^{N\times d}$ ã‚’è€ƒãˆã‚‹ã€‚
ã“ã“ã§ã€$\mathbf{X}$ ã®ç¬¬ $i$ è¡Œã‚’è¡Œãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦ $\mathbf{x}_i^\top\in\mathbb{R}^{1\times d}$ ã¨æ›¸ãã€‚

---

### 2. ä¸­å¿ƒåŒ–ï¼ˆå¹³å‡ã‚’å¼•ã„ãŸåº§æ¨™ç³»ã§è€ƒãˆã‚‹ï¼‰

ã¾ãšåˆ—æ–¹å‘ï¼ˆç‰¹å¾´æ–¹å‘ï¼‰ã®å¹³å‡ã‚’å®šç¾©ã™ã‚‹ã€‚å…¨æˆåˆ† 1 ã®åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã‚’ $\mathbf{1}_N\in\mathbb{R}^{N}$ ã¨ã™ã‚‹ã¨ã€åˆ—å¹³å‡ï¼ˆç‰¹å¾´å¹³å‡ï¼‰ã¯

```math
\boldsymbol{\mu}:=\frac{1}{N}\mathbf{1}_N^\top\mathbf{X}\in\mathbb{R}^{1\times d}
```

ã§ã‚ã‚‹ã€‚ã“ã‚Œã‚’å„ã‚µãƒ³ãƒ—ãƒ«ã«è¤‡è£½ã—ãŸå¹³å‡è¡Œåˆ—ã¯ $\mathbf{1}_N\boldsymbol{\mu}\in\mathbb{R}^{N\times d}$ ã¨ãªã‚‹ã€‚
ã—ãŸãŒã£ã¦ã€ä¸­å¿ƒåŒ–ãƒ‡ãƒ¼ã‚¿ã‚’

```math
\mathbf{X}_c:=\mathbf{X}-\mathbf{1}_N\boldsymbol{\mu}\in\mathbb{R}^{N\times d}
```

ã§å®šç¾©ã™ã‚‹ã€‚

---

### 3. ä½æ¬¡å…ƒéƒ¨åˆ†ç©ºé–“ã¸ã®å°„å½±ï¼ˆã‚¹ã‚³ã‚¢ã®å®šç¾©ï¼‰

å–ã‚Šå‡ºã™ä¸»æˆåˆ†æ•°ã‚’ $k\in\mathbb{N}$ï¼ˆé€šå¸¸ $k\ll d$ï¼‰ã¨ã™ã‚‹ã€‚PCAã¯ã€$\mathbb{R}^d$ å†…ã® $k$ æ¬¡å…ƒéƒ¨åˆ†ç©ºé–“ã‚’é¸ã³ã€ãã®éƒ¨åˆ†ç©ºé–“ã¸ã®ç›´äº¤å°„å½±ã§ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¾ã™ã‚‹ã€‚

ãã®ãŸã‚ã«ã€åŸºåº•ï¼ˆloadingsï¼‰ã‚’

```math
\mathbf{W}\in\mathbb{R}^{d\times k},\qquad \mathbf{W}^\top\mathbf{W}=\mathbf{I}_k
```

ã¨ãŠãï¼ˆåˆ—ãŒç›´äº¤æ­£è¦åŸºåº•ï¼‰ã€‚ã“ã®ã¨ãã€ä¸­å¿ƒåŒ–ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚³ã‚¢ï¼ˆä½æ¬¡å…ƒè¡¨ç¾ï¼‰ã‚’

```math
\mathbf{Z}:=\mathbf{X}_c\mathbf{W}\in\mathbb{R}^{N\times k}
```

ã¨å®šç¾©ã™ã‚‹ã€‚

<details><summary><b>åˆ—ãŒç›´äº¤æ­£è¦åŸºåº•ã¨ã¯</b></summary>

ä¸»æˆåˆ† $j\in{1,\ldots,k}$ ã«å¯¾å¿œã™ã‚‹ $\mathbf{W}$ ã®åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã‚’ $\mathbf{w}_j\in\mathbb{R}^{d}$ ã¨æ›¸ãã¨ã€

```math
\mathbf{W}=
\left[
\mathbf{w}_1\ \mathbf{w}_2\ \cdots\ \mathbf{w}_k
\right]
```

ã§ã‚ã‚‹ã€‚æ¡ä»¶ $\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k$ ã¯ã€ä»»æ„ã® $i,j\in{1,\ldots,k}$ ã«ã¤ã„ã¦

```math
\mathbf{w}_i^\top\mathbf{w}_j=\delta_{ij}
```

ï¼ˆ$\delta_{ij}$ ã¯ã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ã®ãƒ‡ãƒ«ã‚¿ï¼‰ã‚’æ„å‘³ã™ã‚‹ã€‚ã™ãªã‚ã¡

* $i=j$ ãªã‚‰ $\mathbf{w}_i^\top\mathbf{w}_i=1$ï¼ˆé•·ã•ãŒ 1ï¼‰
* $i\neq j$ ãªã‚‰ $\mathbf{w}_i^\top\mathbf{w}_j=0$ï¼ˆäº’ã„ã«ç›´äº¤ï¼‰

ã§ã‚ã‚‹ã€‚

</details>

---

### 4. $\mathbf{W}$ ã®æœ€é©åŒ–ï¼šå†æ§‹æˆèª¤å·®æœ€å°åŒ–

å°„å½±ã—ãŸ $\mathbf{Z}$ ã‹ã‚‰å…ƒã®ç©ºé–“ã¸æˆ»ã™å†æ§‹æˆã‚’

```math
\hat{\mathbf{X}}:=\mathbf{Z}\mathbf{W}^\top=\mathbf{X}_c\mathbf{W}\mathbf{W}^\top
```

ã¨ãŠãã€‚PCAã¯ã€ã“ã®å†æ§‹æˆèª¤å·®ã‚’æœ€å°ã«ã™ã‚‹åŸºåº• $\mathbf{W}^\star$ ã‚’æ±‚ã‚ã‚‹å•é¡Œã¨ã—ã¦å®šç¾©ã§ãã‚‹ï¼š

```math
\mathbf{W}^\star
:=
\operatorname*{arg\,min}_{\mathbf{W}\in\mathbb{R}^{d\times k}}
\left\|\mathbf{X}_c-\mathbf{X}_c\mathbf{W}\mathbf{W}^\top\right\|_F^2
\quad\text{s.t.}\quad
\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k
```

ã“ã“ã§ $\|\cdot\|_F$ ã¯ Frobenius ãƒãƒ«ãƒ ã§ã‚ã‚‹ã€‚

<details><summary><b>Frobeniusãƒãƒ«ãƒ </b></summary>

è¡Œåˆ— $\mathbf{A}\in\mathbb{R}^{N\times M}$ ã®æˆåˆ†ã‚’ $a_{ij}$ ã¨ã™ã‚‹ã¨ã€

```math
\|\mathbf{A}\|_F=\sqrt{\sum_{i=1}^{N}\sum_{j=1}^{M} a_{ij}^2}
```

ã§ã‚ã‚‹ã€‚ã¾ãŸã€ãƒˆãƒ¬ãƒ¼ã‚¹ $\mathrm{Tr}$ ã‚’ç”¨ã„ã¦

```math
\|\mathbf{A}\|_F^2=\mathrm{Tr}(\mathbf{A}^\top\mathbf{A})
```

ã¨æ›¸ã‘ã‚‹ï¼ˆå³è¾ºã¯å…¨æˆåˆ†äºŒä¹—å’Œã«ä¸€è‡´ã™ã‚‹ï¼‰ã€‚

</details>

---

### 5. truncated SVD ã«ã‚ˆã‚‹è§£æ³•ï¼ˆå›ºæœ‰å€¤åˆ†è§£ã‚ˆã‚Šæ•°å€¤çš„ã«å®‰å®šï¼‰

ä¸­å¿ƒåŒ–ãƒ‡ãƒ¼ã‚¿ $\mathbf{X}_c\in\mathbb{R}^{N\times d}$ ã«å¯¾ã—ã¦ã€ä¸Šä½ $k$ æˆåˆ†ã®ã¿ã‚’ç”¨ã„ã‚‹ truncated SVD ã‚’è€ƒãˆã‚‹ï¼š

```math
\mathbf{X}_c \approx \mathbf{U}_k\boldsymbol{\Sigma}_k\mathbf{V}_k^\top
```

ã“ã“ã§

* $\mathbf{U}_k\in\mathbb{R}^{N\times k}$ ã¨ $\mathbf{V}_k\in\mathbb{R}^{d\times k}$ ã¯åˆ—ç›´äº¤ã§ã‚ã‚‹ï¼š

```math
\mathbf{U}_k^\top\mathbf{U}_k=\mathbf{I}_k,\qquad
\mathbf{V}_k^\top\mathbf{V}_k=\mathbf{I}_k
```

* $\boldsymbol{\Sigma}_k\in\mathbb{R}^{k\times k}$ ã¯ç‰¹ç•°å€¤ã®å¯¾è§’è¡Œåˆ—ã§ã‚ã‚‹ï¼š

```math
\boldsymbol{\Sigma}_k=\mathrm{diag}(\sigma_1,\ldots,\sigma_k),\qquad
\sigma_1\ge\sigma_2\ge\cdots\ge\sigma_k>0
```

#### 5.1 è§£ã®å½¢ï¼š$\mathbf{W}^\star$ ã¯ $\mathbf{V}_k$

PCA ã®æœ€é©åŸºåº•ï¼ˆloadingsï¼‰ã¯

```math
\mathbf{W}^\star=\mathbf{V}_k\in\mathbb{R}^{d\times k}
```

ã§ä¸ãˆã‚‰ã‚Œã‚‹ã€‚ã™ãªã‚ã¡ã€ç‰¹ç•°å€¤ $\sigma_i$ ãŒå¤§ãã„é †ã«ä¸Šä½ $k$ æœ¬ã®å³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¸»æˆåˆ†æ–¹å‘ã¨ã—ã¦æ¡ç”¨ã™ã‚Œã°ã‚ˆã„ã€‚


#### 5.2 ã‚¹ã‚³ã‚¢ã®å½¢ï¼š$\mathbf{Z}$ ã¯ã€Œå·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ« Ã— ç‰¹ç•°å€¤ã€

$\mathbf{Z}:=\mathbf{X}_c\mathbf{W}^\star$ ã‚ˆã‚Š

```math
\mathbf{Z}
=
\mathbf{X}_c\mathbf{V}_k
\approx
\mathbf{U}_k\boldsymbol{\Sigma}_k\mathbf{V}_k^\top\mathbf{V}_k
=
\mathbf{U}_k\boldsymbol{\Sigma}_k
\in\mathbb{R}^{N\times k}
```

ã¨ãªã‚‹ã€‚ã—ãŸãŒã£ã¦ã€ã‚¹ã‚³ã‚¢ã¯ **ã€Œå·¦ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ« Ã— ç‰¹ç•°å€¤ã€** ã¨ã—ã¦ç›´æ¥å¾—ã‚‰ã‚Œã‚‹ã€‚

#### 5.3 åˆ†æ•£ï¼ˆå›ºæœ‰å€¤ï¼‰ã¨ç‰¹ç•°å€¤ï¼š$\lambda_i=\sigma_i^2/N$ ã¨å¯„ä¸ç‡
ã“ã®ç¯€ã®ç›®çš„ã¯ã€ä¸»æˆåˆ† $i$ ã®ã€Œåˆ†æ•£ï¼ˆå›ºæœ‰å€¤ï¼‰ã€$\lambda_i$ ãŒã€SVD ã®ç‰¹ç•°å€¤ $\sigma_i$ ã¨

```math
\lambda_i=\frac{\sigma_i^2}{N}
```

ã§çµã°ã‚Œã€ã•ã‚‰ã«ãã‚ŒãŒã€Œå°„å½±ã‚¹ã‚³ã‚¢ã®åˆ†æ•£ã€ã¨ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã“ã¨ã§ã‚ã‚‹ã€‚

##### (1) å…±åˆ†æ•£è¡Œåˆ—ã¨ PCA ã®å›ºæœ‰å€¤å•é¡Œ

ä¸­å¿ƒåŒ–ãƒ‡ãƒ¼ã‚¿ $\mathbf{X}_c\in\mathbb{R}^{N\times d}$ ã«å¯¾ã—ã€å…±åˆ†æ•£è¡Œåˆ—ã‚’

```math
\mathbf{S}:=\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c\in\mathbb{R}^{d\times d}
```

ã¨å®šç¾©ã™ã‚‹ï¼ˆåˆ†æ¯ã‚’ $N$ ã¨ã™ã‚‹æµå„€ï¼‰ã€‚PCA ã¯ $\mathbf{S}$ ã®å›ºæœ‰å€¤å•é¡Œ

```math
\mathbf{S}\mathbf{v}_i=\lambda_i\mathbf{v}_i,\qquad \|\mathbf{v}_i\|_2=1
```

ã«ã‚ˆã‚Šã€ä¸»æˆåˆ†æ–¹å‘ $\mathbf{v}_i$ ã¨ã€ãã®æ–¹å‘ã®åˆ†æ•£ $\lambda_i$ ã‚’å¾—ã‚‹ã€‚

##### (2) SVD ã‹ã‚‰ $\lambda_i=\sigma_i^2/N$ ã‚’å¾—ã‚‹

full SVD ã‚’

$$\mathbf{X}_c=\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^\top$$

ã¨ã™ã‚‹ï¼ˆ$\boldsymbol{\Sigma}=\mathrm{diag}(\sigma_1,\ldots,\sigma_r)$ï¼‰ã€‚ã“ã®ã¨ã

```math
\mathbf{S}
=
\frac{1}{N}\mathbf{X}_c^\top\mathbf{X}_c
=
\frac{1}{N}\mathbf{V}\boldsymbol{\Sigma}^2\mathbf{V}^\top
```

ãŒæˆã‚Šç«‹ã¤ã€‚ã‚ˆã£ã¦ $\mathbf{S}$ ã®å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã¯ $\mathbf{V}$ ã®åˆ—ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã«ä¸€è‡´ã—ã€å¯¾å¿œã™ã‚‹å›ºæœ‰å€¤ã¯

```math
\lambda_i=\frac{\sigma_i^2}{N}
```

ã¨ãªã‚‹ã€‚
ï¼ˆtruncated SVD ã®å ´åˆã‚‚ã€ä¸Šä½ $k$ æˆåˆ†ã«ã¤ã„ã¦åŒã˜é–¢ä¿‚ãŒæˆã‚Šç«‹ã¤ã¨è§£é‡ˆã™ã‚Œã°ã‚ˆã„ã€‚ï¼‰

##### (3) å°„å½±ã‚¹ã‚³ã‚¢ã®åˆ†æ•£ãŒ $\lambda_i$ ã«ä¸€è‡´ã™ã‚‹

ä¸»æˆåˆ†æ–¹å‘ $\mathbf{v}_i$ ã¸ã®å°„å½±ã‚¹ã‚³ã‚¢ï¼ˆ1 æ¬¡å…ƒè¡¨ç¾ï¼‰ã‚’

```math
\mathbf{z}_i:=\mathbf{X}_c\mathbf{v}_i\in\mathbb{R}^{N}
```

ã¨å®šç¾©ã™ã‚‹ã€‚ä¸­å¿ƒåŒ–ã«ã‚ˆã‚Š $\mathbf{z}_i$ ã®å¹³å‡ã¯ 0 ã§ã‚ã‚‹ãŸã‚ã€åˆ†æ•£ã‚’

```math
\mathrm{Var}(\mathbf{z}_i):=\frac{1}{N}\|\mathbf{z}_i\|_2^2
```

ã¨ãŠãï¼ˆã“ã®å®šç¾©ã¯ä¸Šã§æ¡ç”¨ã—ãŸ $\mathbf{S}$ ã®åˆ†æ¯ $N$ ã¨æ•´åˆã™ã‚‹ï¼‰ã€‚

ã™ã‚‹ã¨

```math
\mathrm{Var}(\mathbf{z}_i)
=
\frac{1}{N}\mathbf{z}_i^\top\mathbf{z}_i
=
\frac{1}{N}\left(\mathbf{X}_c\mathbf{v}_i\right)^\top\left(\mathbf{X}_c\mathbf{v}_i\right)
=
\mathbf{v}_i^\top\mathbf{S}\mathbf{v}_i
```

ã§ã‚ã‚Šã€ã•ã‚‰ã«å›ºæœ‰å€¤å•é¡Œ $\mathbf{S}\mathbf{v}_i=\lambda_i\mathbf{v}_i$ ã¨ $|\mathbf{v}_i|_2=1$ ã‚ˆã‚Š

```math
\mathrm{Var}(\mathbf{z}_i)=\mathbf{v}_i^\top\mathbf{S}\mathbf{v}_i=\lambda_i
```

ãŒå¾—ã‚‰ã‚Œã‚‹ã€‚ã—ãŸãŒã£ã¦

```math
\mathrm{Var}(\mathbf{z}_i)=\lambda_i=\frac{\sigma_i^2}{N}
```

ãŒæˆç«‹ã™ã‚‹ã€‚
è¨€ã„æ›ãˆã‚‹ã¨ã€$\sigma_i^2$ ã¯å°„å½±ã‚¹ã‚³ã‚¢ã®ã€Œç·ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€ã«å¯¾å¿œã—ã€ãã® $1/N$ ãŒåˆ†æ•£ã«ãªã‚‹ã€‚

##### (4) å¯„ä¸ç‡ï¼ˆexplained variance ratioï¼‰

å¯„ä¸ç‡ï¼ˆexplained variance ratioï¼‰ã¯ã€åˆ†æ•£ï¼ˆå›ºæœ‰å€¤ï¼‰ã§æ­£è¦åŒ–ã—ãŸæ¯”ã¨ã—ã¦å®šç¾©ã•ã‚Œã‚‹ã€‚ä¸Šä½ $k$ æˆåˆ†ã«å¯¾ã™ã‚‹ **éƒ¨åˆ†å¯„ä¸ç‡**ã¯

```math
\mathrm{EVR}_i^{(k)}
:=
\frac{\lambda_i}{\sum_{j=1}^{k}\lambda_j}
=
\frac{\sigma_i^2}{\sum_{j=1}^{k}\sigma_j^2}
\qquad (i=1,\ldots,k)
```

ã§ã‚ã‚‹ã€‚


---

#### 5.4 ãªãœã“ã‚ŒãŒæœ€é©è§£ã«ãªã‚‹ã‹ï¼ˆå†æ§‹æˆèª¤å·®æœ€å°åŒ– â‡” åˆ†æ•£æœ€å¤§åŒ–ï¼‰

å°„å½±è¡Œåˆ—ã‚’

```math
\mathbf{P}:=\mathbf{W}\mathbf{W}^\top\in\mathbb{R}^{d\times d}
```

ã¨ãŠãã¨ã€$\mathbf{P}$ ã¯å¯¾ç§°ã‹ã¤å†ªç­‰

```math
\mathbf{P}^\top=\mathbf{P},\qquad \mathbf{P}^2=\mathbf{P}
```

ã‚’æº€ãŸã—ã€$\mathrm{rank}(\mathbf{P})=k$ ã®ç›´äº¤å°„å½±ã§ã‚ã‚‹ã€‚

ç›®çš„é–¢æ•°ã¯

```math
\left\|\mathbf{X}_c-\mathbf{X}_c\mathbf{P}\right\|_F^2
=
\mathrm{Tr}(\mathbf{X}_c^\top\mathbf{X}_c)
-
\mathrm{Tr}(\mathbf{P}\mathbf{X}_c^\top\mathbf{X}_c)
```

ã¨å¤‰å½¢ã§ãã‚‹ã€‚ç¬¬1é … $\mathrm{Tr}(\mathbf{X}_c^\top\mathbf{X}_c)=|\mathbf{X}_c|_F^2$ ã¯ $\mathbf{W}$ ã«ä¾ã‚‰ãªã„å®šæ•°ãªã®ã§ã€æœ€å°åŒ–ã¯æ¬¡ã®æœ€å¤§åŒ–ã«ç­‰ä¾¡ã§ã‚ã‚‹ï¼š

```math
\mathbf{W}^\star
=
\operatorname*{arg\,max}_{\mathbf{W}^\top\mathbf{W}=\mathbf{I}_k}
\mathrm{Tr}\!\left(\mathbf{W}^\top \mathbf{X}_c^\top\mathbf{X}_c \mathbf{W}\right)
```

ã“ã®æœ€å¤§åŒ–ã®è§£ã¯ã€$\mathbf{X}_c^\top\mathbf{X}_c$ ã®å›ºæœ‰å€¤ãŒå¤§ãã„æ–¹å‘ã‚’ä¸Šä½ $k$ æœ¬å–ã‚‹ã“ã¨ã«å¯¾å¿œã™ã‚‹ï¼ˆRayleighâ€“Ritz / Ky Fanï¼‰ã€‚truncated SVD ã¯ãã®ä¸Šä½æˆåˆ†ã‚’ç›´æ¥è¿”ã™ãŸã‚ã€çµå±€ $\mathbf{W}^\star=\mathbf{V}_k$ ãŒå¾—ã‚‰ã‚Œã‚‹ã€‚

---

## Pytorchå®Ÿè£…

```python
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Union

import torch

Tensor = torch.Tensor
PathLike = Union[str, Path]


def _as_tensor_2d(x: Any, *, dtype: Optional[torch.dtype], device: Optional[torch.device]) -> Tensor:
    """å…¥åŠ›ã‚’2æ¬¡å…ƒfloat Tensorã¨ã—ã¦æ¤œè¨¼ãƒ»æ•´å½¢ã™ã‚‹ï¼ˆFail Fastï¼‰ã€‚

    Parameters
    ----------
    x : Any
        å…¥åŠ›ã€‚torch.Tensor ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
    dtype : torch.dtype, optional
        æŒ‡å®šæ™‚ã€dtype ã«å¤‰æ›ã™ã‚‹ã€‚
    device : torch.device, optional
        æŒ‡å®šæ™‚ã€device ã«ç§»å‹•ã™ã‚‹ã€‚

    Returns
    -------
    X : torch.Tensor
        å½¢çŠ¶ (N, d) ã®2æ¬¡å…ƒæµ®å‹•å°æ•°ç‚¹ãƒ†ãƒ³ã‚½ãƒ«ã€‚

    Raises
    ------
    TypeError
        x ãŒ torch.Tensor ã§ãªã„ã€ã¾ãŸã¯æµ®å‹•å°æ•°ç‚¹ã§ãªã„å ´åˆã€‚
    ValueError
        x ãŒ2æ¬¡å…ƒã§ãªã„ã€ã¾ãŸã¯ç©ºã®å ´åˆã€‚
    """
    if not isinstance(x, torch.Tensor):
        raise TypeError(f"X ã¯ torch.Tensor ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {type(x)}")
    if x.ndim != 2:
        raise ValueError(f"X ã¯2æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ« (N, d) ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: shape={tuple(x.shape)}")
    if x.numel() == 0:
        raise ValueError("X ã¯ç©ºã§ã‚ã£ã¦ã¯ãªã‚Šã¾ã›ã‚“ã€‚")
    if not x.is_floating_point():
        raise TypeError(f"X ã¯æµ®å‹•å°æ•°ç‚¹ãƒ†ãƒ³ã‚½ãƒ«ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: dtype={x.dtype}")

    if dtype is not None and x.dtype != dtype:
        x = x.to(dtype=dtype)
    if device is not None and x.device != device:
        x = x.to(device=device)
    return x


def _safe_div(a: Tensor, b: Tensor, eps: float) -> Tensor:
    """ã‚¼ãƒ­å‰²ã‚’é¿ã‘ãŸå®‰å…¨ãªé™¤ç®— a / max(b, eps)ã€‚"""
    return a / b.clamp_min(eps)


@dataclass(frozen=True)
class PCAState:
    """PCAã®ä¿å­˜ç”¨çŠ¶æ…‹ï¼ˆtorch.saveã®payloadã«è¼‰ã›ã‚‹ï¼‰ã€‚"""
    n_components: int
    center: bool
    whiten: bool
    eps: float
    mean: Tensor
    loadings: Tensor
    singular_values: Tensor
    explained_variance: Tensor
    explained_variance_ratio: Tensor
    n_samples: int
    dtype: str
    device: str


class PCA:
    r"""PyTorchå®Ÿè£…ã®PCAï¼ˆSVDãƒ™ãƒ¼ã‚¹ã€GPUå¯¾å¿œï¼‰ã€‚

    æœ¬ã‚¯ãƒ©ã‚¹ã¯æ¬¡ã®å®šå¼åŒ–ã«å³å¯†ã«å¾“ã†ã€‚

    **ä¸­å¿ƒåŒ–**
    - å…¥åŠ›è¡Œåˆ—ã‚’ :math:`\mathbf{X}\in\mathbb{R}^{N\times d}` ã¨ã™ã‚‹ã€‚
    - ç‰¹å¾´é‡å¹³å‡ :math:`\boldsymbol{\mu}\in\mathbb{R}^{d}` ã‚’ç”¨ã„ã¦
      :math:`\mathbf{X}_c = \mathbf{X} - \mathbf{1}\boldsymbol{\mu}^{\top}` ã¨ã™ã‚‹ã€‚

    **ï¼ˆæ‰“ã¡åˆ‡ã‚Šï¼‰SVD**
    - :math:`\mathbf{X}_c \approx \mathbf{U}_k \boldsymbol{\Sigma}_k \mathbf{V}_k^{\top}`

    **ä¸»è»¸ï¼ˆloadingsï¼‰ã¨ã‚¹ã‚³ã‚¢ï¼ˆscoresï¼‰**
    - loadingsï¼ˆä¸»æˆåˆ†æ–¹å‘ï¼‰: :math:`\mathbf{W}=\mathbf{V}_k \in \mathbb{R}^{d\times k}`
    - scoresï¼ˆä¸»æˆåˆ†å¾—ç‚¹ï¼‰: :math:`\mathbf{Z}=\mathbf{X}_c\mathbf{W}\in\mathbb{R}^{N\times k}`

    Parameters
    ----------
    n_components : int
        ä¸»æˆåˆ†æ•° :math:`k`ã€‚
    center : bool, default=True
        True ã®å ´åˆã€ç‰¹å¾´é‡å¹³å‡ã‚’å¼•ã„ã¦ã‹ã‚‰SVDã‚’è¡Œã†ã€‚
    whiten : bool, default=False
        True ã®å ´åˆã€transform å‡ºåŠ› :math:`\mathbf{Z}` ã‚’
        :math:`\sqrt{\lambda_i}`ï¼ˆæˆåˆ†åˆ†æ•£ï¼‰ã§å‰²ã‚Šã€å„æˆåˆ†ã‚’å˜ä½åˆ†æ•£åŒ–ã™ã‚‹ã€‚
    eps : float, default=1e-12
        æ•°å€¤å®‰å®šåŒ–ï¼ˆã‚¼ãƒ­å‰²å›é¿ï¼‰ç”¨ã®å°ã•ã„å®šæ•°ã€‚
    dtype : torch.dtype, optional
        fit/transform æ™‚ã«å†…éƒ¨ã§ã“ã®dtypeã¸æƒãˆã‚‹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¥åŠ›ã«å¾“ã†ï¼‰ã€‚
    device : str | torch.device, optional
        fit/transform æ™‚ã«å†…éƒ¨ã§ã“ã®deviceã¸æƒãˆã‚‹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¥åŠ›ã«å¾“ã†ï¼‰ã€‚

    Attributes
    ----------
    mean_ : torch.Tensor
        ç‰¹å¾´é‡å¹³å‡ :math:`\boldsymbol{\mu}`ã€‚å½¢çŠ¶ (d,)ã€‚
        center=False ã®å ´åˆã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã€‚
    loadings_ : torch.Tensor
        loadingsï¼ˆä¸»è»¸ï¼‰: :math:`\mathbf{W}`ã€‚å½¢çŠ¶ (d, k)ã€‚
        å„åˆ—ã¯ç›´äº¤è¦æ ¼åŒ–ã•ã‚Œã‚‹ã€‚
    components_ : torch.Tensor
        sklearnäº’æ›ã®åˆ¥åã€‚loadings_ ã¨åŒä¸€å‚ç…§ã€‚
    singular_values_ : torch.Tensor
        ç‰¹ç•°å€¤ :math:`(\sigma_1,\ldots,\sigma_k)`ã€‚å½¢çŠ¶ (k,)ã€‚
    explained_variance_ : torch.Tensor
        å„æˆåˆ†ã®åˆ†æ•£ :math:`\lambda_i`ã€‚å½¢çŠ¶ (k,)ã€‚
        æœ¬å®Ÿè£…ã§ã¯ **åˆ†æ¯N** ã®æµå„€ã§ :math:`\lambda_i=\sigma_i^2 / N` ã‚’æ¡ç”¨ã™ã‚‹ã€‚
    explained_variance_ratio_ : torch.Tensor
        ä¿æŒã—ãŸkæˆåˆ†å†…ã§æ­£è¦åŒ–ã—ãŸå¯„ä¸ç‡ã€‚
        :math:`\lambda_i / \sum_{j=1}^{k}\lambda_j`ã€‚å½¢çŠ¶ (k,)ã€‚
    n_samples_ : int
        fit ã«ç”¨ã„ãŸã‚µãƒ³ãƒ—ãƒ«æ•° :math:`N`ã€‚
    fitted_ : bool
        å­¦ç¿’æ¸ˆã¿ãƒ•ãƒ©ã‚°ã€‚

    Notes
    -----
    - SVDã¯ `torch.linalg.svd(Xc, full_matrices=False)` ã‚’ç”¨ã„ã‚‹ã€‚
      ã“ã‚Œã¯å³å¯†ã ãŒã€å¤§è¦æ¨¡ (N,dãŒéå¸¸ã«å¤§ãã„) ã§ã¯ãƒ¡ãƒ¢ãƒª/è¨ˆç®—ãŒé‡ã„ã€‚
      è¿‘ä¼¼SVDï¼ˆrandomizedç­‰ï¼‰ã‚’å°å…¥ã—ãŸã„å ´åˆã¯åˆ¥é€”è¨­è¨ˆã™ã‚‹ã€‚
    - explained_variance_ratio_ ã¯ã€Œä¸Šä½kå†…ã§ã®æ­£è¦åŒ–ã€ã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚
      å…¨æˆåˆ†ï¼ˆrankå…¨ä½“ï¼‰ã§ã®EVRãŒå¿…è¦ãªã‚‰å…¨ç‰¹ç•°å€¤ãŒå¿…è¦ã€‚

    Raises
    ------
    ValueError
        å…¥åŠ›shapeä¸æ­£ã€n_componentsãŒç¯„å›²å¤–ãªã©ã€‚
    TypeError
        å…¥åŠ›ãŒtorch.Tensorã§ãªã„ã€ã¾ãŸã¯æµ®å‹•å°æ•°ç‚¹ã§ãªã„å ´åˆã€‚

    Examples
    --------
    >>> import torch
    >>> X = torch.randn(1000, 256, device="cuda")
    >>> pca = PCA(n_components=32, center=True, whiten=False).fit(X)
    >>> Z = pca.transform(X)  # (1000, 32)
    >>> pca.save("pca.pt")
    >>> pca2 = PCA.load("pca.pt", map_location="cuda")
    >>> torch.allclose(pca.loadings, pca2.loadings)
    True
    """

    def __init__(
        self,
        n_components: int,
        *,
        center: bool = True,
        whiten: bool = False,
        eps: float = 1e-12,
        dtype: Optional[torch.dtype] = None,
        device: Optional[Union[str, torch.device]] = None,
    ) -> None:
        if not isinstance(n_components, int) or n_components <= 0:
            raise ValueError(f"n_components ã¯æ­£ã®intã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {n_components}")
        if not isinstance(center, bool):
            raise TypeError("center ã¯ bool ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        if not isinstance(whiten, bool):
            raise TypeError("whiten ã¯ bool ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        if not isinstance(eps, (float, int)) or float(eps) <= 0.0:
            raise ValueError(f"eps ã¯æ­£ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: got {eps}")

        self.n_components: int = n_components
        self.center: bool = center
        self.whiten: bool = whiten
        self.eps: float = float(eps)

        self._dtype: Optional[torch.dtype] = dtype
        self._device: Optional[torch.device] = torch.device(device) if device is not None else None

        self.mean_: Optional[Tensor] = None
        self.loadings_: Optional[Tensor] = None
        self.components_: Optional[Tensor] = None
        self.singular_values_: Optional[Tensor] = None
        self.explained_variance_: Optional[Tensor] = None
        self.explained_variance_ratio_: Optional[Tensor] = None
        self.n_samples_: Optional[int] = None
        self.fitted_: bool = False

    @property
    def loadings(self) -> Tensor:
        """loadings_ï¼ˆä¸»è»¸ï¼‰ã¸ã®åˆ¥åã‚¢ã‚¯ã‚»ã‚¹ã€‚

        Returns
        -------
        loadings : torch.Tensor
            å½¢çŠ¶ (d, k) ã®ä¸»è»¸è¡Œåˆ—ã€‚

        Raises
        ------
        RuntimeError
            æœªå­¦ç¿’ã®å ´åˆã€‚
        """
        if not self.fitted_ or self.loadings_ is None:
            raise RuntimeError("PCAã¯æœªå­¦ç¿’ã§ã™ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        return self.loadings_

    @property
    def mean(self) -> Tensor:
        """mean_ï¼ˆç‰¹å¾´é‡å¹³å‡ï¼‰ã¸ã®åˆ¥åã‚¢ã‚¯ã‚»ã‚¹ã€‚"""
        if not self.fitted_ or self.mean_ is None:
            raise RuntimeError("PCAã¯æœªå­¦ç¿’ã§ã™ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        return self.mean_

    def fit(self, X: Tensor) -> "PCA":
        """PCAã‚’å­¦ç¿’ã™ã‚‹ï¼ˆä¸­å¿ƒåŒ–â†’SVDï¼‰ã€‚

        Parameters
        ----------
        X : torch.Tensor
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚å½¢çŠ¶ (N, d) ã®æµ®å‹•å°æ•°ç‚¹ãƒ†ãƒ³ã‚½ãƒ«ã€‚

        Returns
        -------
        self : PCA
            å­¦ç¿’æ¸ˆã¿ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚

        Raises
        ------
        ValueError
            n_components ãŒ min(N, d) ã‚’è¶…ãˆã‚‹å ´åˆãªã©ã€‚
        TypeError
            å…¥åŠ›ãŒtorch.Tensorã§ãªã„ã€ã¾ãŸã¯æµ®å‹•å°æ•°ç‚¹ã§ãªã„å ´åˆã€‚
        """
        X = _as_tensor_2d(X, dtype=self._dtype, device=self._device)
        n, d = int(X.shape[0]), int(X.shape[1])

        k = self.n_components
        if k > min(n, d):
            raise ValueError(f"n_components={k} ã¯ min(N,d)={min(n,d)} ä»¥ä¸‹ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

        if self.center:
            mean = X.mean(dim=0)  # (d,)
            Xc = X - mean
        else:
            mean = torch.zeros(d, dtype=X.dtype, device=X.device)
            Xc = X

        # Xc = U S Vh
        _, S, Vh = torch.linalg.svd(Xc, full_matrices=False)

        S_k = S[:k]  # (k,)
        V_k = Vh[:k, :].T.contiguous()  # (d, k)

        explained_var = (S_k * S_k) / float(n)  # lambda_i = sigma_i^2 / N
        evr = _safe_div(explained_var, explained_var.sum(), eps=self.eps)

        self.mean_ = mean
        self.loadings_ = V_k
        self.components_ = self.loadings_
        self.singular_values_ = S_k
        self.explained_variance_ = explained_var
        self.explained_variance_ratio_ = evr
        self.n_samples_ = n
        self.fitted_ = True
        return self

    def transform(self, X: Tensor) -> Tensor:
        """å­¦ç¿’æ¸ˆã¿PCAç©ºé–“ã¸å°„å½±ã™ã‚‹ã€‚

        Parameters
        ----------
        X : torch.Tensor
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚å½¢çŠ¶ (N, d)ã€‚

        Returns
        -------
        Z : torch.Tensor
            ä¸»æˆåˆ†å¾—ç‚¹ã€‚å½¢çŠ¶ (N, k)ã€‚
            whiten=True ã®å ´åˆã€å„åˆ—ã‚’ sqrt(explained_variance_) ã§å‰²ã‚‹ã€‚

        Raises
        ------
        RuntimeError
            æœªå­¦ç¿’ã®å ´åˆã€‚
        ValueError
            å…¥åŠ›ã®æ¬¡å…ƒ d ãŒå­¦ç¿’æ™‚ã¨ä¸€è‡´ã—ãªã„å ´åˆã€‚
        """
        if not self.fitted_:
            raise RuntimeError("PCAã¯æœªå­¦ç¿’ã§ã™ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        assert self.mean_ is not None
        assert self.loadings_ is not None
        assert self.explained_variance_ is not None

        X = _as_tensor_2d(X, dtype=self.mean_.dtype, device=self.mean_.device)
        if int(X.shape[1]) != int(self.mean_.shape[0]):
            raise ValueError(f"å…¥åŠ›d={int(X.shape[1])}ãŒå­¦ç¿’æ™‚d={int(self.mean_.shape[0])}ã¨ä¸€è‡´ã—ã¾ã›ã‚“ã€‚")

        Xc = X - self.mean_ if self.center else X
        Z = Xc @ self.loadings_

        if self.whiten:
            Z = _safe_div(Z, torch.sqrt(self.explained_variance_), eps=self.eps)
        return Z

    def fit_transform(self, X: Tensor) -> Tensor:
        """å­¦ç¿’ã¨å¤‰æ›ã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œã™ã‚‹ã€‚

        Parameters
        ----------
        X : torch.Tensor
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚å½¢çŠ¶ (N, d)ã€‚

        Returns
        -------
        Z : torch.Tensor
            ä¸»æˆåˆ†å¾—ç‚¹ã€‚å½¢çŠ¶ (N, k)ã€‚
        """
        self.fit(X)
        return self.transform(X)

    def _state_dict(self) -> Dict[str, Any]:
        if not self.fitted_:
            raise RuntimeError("æœªå­¦ç¿’ã®ãŸã‚ä¿å­˜ã§ãã¾ã›ã‚“ã€‚fit() ã‚’å…ˆã«å‘¼ã‚“ã§ãã ã•ã„ã€‚")
        assert self.mean_ is not None
        assert self.loadings_ is not None
        assert self.singular_values_ is not None
        assert self.explained_variance_ is not None
        assert self.explained_variance_ratio_ is not None
        assert self.n_samples_ is not None

        state = PCAState(
            n_components=self.n_components,
            center=self.center,
            whiten=self.whiten,
            eps=self.eps,
            mean=self.mean_.detach().cpu(),
            loadings=self.loadings_.detach().cpu(),
            singular_values=self.singular_values_.detach().cpu(),
            explained_variance=self.explained_variance_.detach().cpu(),
            explained_variance_ratio=self.explained_variance_ratio_.detach().cpu(),
            n_samples=int(self.n_samples_),
            dtype=str(self.mean_.dtype),
            device=str(self.mean_.device),
        )
        return {"pca_state": state}

    def save(self, path: PathLike) -> None:
        """å­¦ç¿’æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã€‚

        Parameters
        ----------
        path : str | pathlib.Path
            ä¿å­˜å…ˆãƒ‘ã‚¹ï¼ˆä¾‹: "pca.pt"ï¼‰ã€‚

        Returns
        -------
        None

        Raises
        ------
        RuntimeError
            æœªå­¦ç¿’ã®å ´åˆã€‚
        """
        p = Path(path)
        p.parent.mkdir(parents=True, exist_ok=True)
        torch.save(self._state_dict(), p)

    @classmethod
    def load(
        cls,
        path: PathLike,
        *,
        map_location: Optional[Union[str, torch.device]] = None,
        device: Optional[Union[str, torch.device]] = None,
        dtype: Optional[torch.dtype] = None,
    ) -> "PCA":
        """ä¿å­˜æ¸ˆã¿PCAã‚’èª­ã¿è¾¼ã‚€ã€‚

        Parameters
        ----------
        path : str | pathlib.Path
            save() ã§ä¿å­˜ã—ãŸ .pt ã¸ã®ãƒ‘ã‚¹ã€‚
        map_location : str | torch.device, optional
            torch.load ã«æ¸¡ã™ map_locationï¼ˆä¾‹: "cpu" / "cuda"ï¼‰ã€‚
        device : str | torch.device, optional
            èª­ã¿è¾¼ã¿å¾Œã«æ˜ç¤ºçš„ã«ç§»ã™deviceã€‚æŒ‡å®šã—ãŸå ´åˆ map_location ã‚ˆã‚Šå„ªå…ˆã€‚
        dtype : torch.dtype, optional
            èª­ã¿è¾¼ã¿å¾Œã«ã“ã®dtypeã¸ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹ã€‚

        Returns
        -------
        pca : PCA
            å¾©å…ƒã•ã‚ŒãŸPCAã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã€‚

        Raises
        ------
        FileNotFoundError
            path ãŒå­˜åœ¨ã—ãªã„å ´åˆã€‚
        ValueError
            ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ãªå ´åˆã€‚
        """
        p = Path(path)
        if not p.exists():
            raise FileNotFoundError(str(p))

        payload = torch.load(p, map_location=map_location)
        if not isinstance(payload, dict) or "pca_state" not in payload:
            raise ValueError("PCAãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆ'pca_state' ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

        state = payload["pca_state"]
        if not isinstance(state, PCAState):
            raise ValueError("PCAãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå½¢å¼ãŒä¸æ­£ã§ã™ï¼ˆpca_state ãŒ PCAState ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚")

        pca = cls(
            n_components=state.n_components,
            center=state.center,
            whiten=state.whiten,
            eps=state.eps,
            dtype=dtype,
            device=torch.device(device) if device is not None else None,
        )

        tgt_device: Optional[torch.device]
        if device is not None:
            tgt_device = torch.device(device)
        elif map_location is not None:
            tgt_device = torch.device(map_location)
        else:
            tgt_device = None

        mean = state.mean
        loadings = state.loadings
        sv = state.singular_values
        ev = state.explained_variance
        evr = state.explained_variance_ratio

        if dtype is not None:
            mean = mean.to(dtype=dtype)
            loadings = loadings.to(dtype=dtype)
            sv = sv.to(dtype=dtype)
            ev = ev.to(dtype=dtype)
            evr = evr.to(dtype=dtype)

        if tgt_device is not None:
            mean = mean.to(device=tgt_device)
            loadings = loadings.to(device=tgt_device)
            sv = sv.to(device=tgt_device)
            ev = ev.to(device=tgt_device)
            evr = evr.to(device=tgt_device)

        pca.mean_ = mean
        pca.loadings_ = loadings
        pca.components_ = pca.loadings_
        pca.singular_values_ = sv
        pca.explained_variance_ = ev
        pca.explained_variance_ratio_ = evr
        pca.n_samples_ = int(state.n_samples)
        pca.fitted_ = True
        return pca
```